{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "from eflow.foundation import DataPipeline,DataFrameTypes\n",
    "from eflow.data_analysis import FeatureAnalysis, NullAnalysis\n",
    "from eflow.model_analysis import ClassificationAnalysis\n",
    "from eflow.data_pipeline_segments import FeatureTransformer, TypeFixer, DataEncoder\n",
    "from eflow.utils.modeling_utils import optimize_model_grid\n",
    "from eflow.utils.eflow_utils import get_type_holder_from_pipeline, remove_unconnected_pipeline_segments\n",
    "from eflow.utils.math_utils import get_unbalanced_threshold\n",
    "from eflow.utils.sys_utils import create_dir_structure\n",
    "from eflow.utils.eflow_utils import create_color_dict_for_features\n",
    "from eflow.utils.pandas_utils import data_types_table, value_counts_table, suggest_removal_features, missing_values_table\n",
    "from eflow.widgets import ColorLabelingWidget\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scikitplot as skplt\n",
    "from nltk.corpus import words\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.getipython import get_ipython\n",
    "import ipython_blocking\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Additional add ons\n",
    "# !pip install pandasgui\n",
    "# !pip install pivottablejs\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download natural language processing utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ericcacciavillani/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/ericcacciavillani/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ericcacciavillani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juypter notebook generating cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note: Replace if set to True will remove all the contents of whatever cell it is called in. But it can be undone with a simple CMD + Z. ðŸ™‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: http://tinyurl.com/y6mghyzl\n",
    "def create_new_cell(contents,\n",
    "                    replace=False):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Creates a new jupyter cell.\n",
    "    \"\"\"\n",
    "    shell = get_ipython()\n",
    "    shell.set_next_input(contents,\n",
    "                         replace=replace)\n",
    "\n",
    "def __format_list_to_string(list_name,\n",
    "                            list_contents):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Converts a list to a string and adds newlines for formating.\n",
    "    \"\"\"\n",
    "    output_str = f\"{list_name} = [\"\n",
    "    escape_seq_count = 0\n",
    "    final_index = len(list_contents) - 1\n",
    "    req_spacing = len(output_str)\n",
    "\n",
    "    for i,element in enumerate(list_contents):\n",
    "        if i == final_index:\n",
    "            output_str += f'\\\"{element}\\\"'\n",
    "        else:\n",
    "            output_str += f'\\\"{element}\\\",'\n",
    "        \n",
    "        if len(output_str.split(\"\\n\")[escape_seq_count]) > 78:\n",
    "            output_str += \"\\n\"\n",
    "            output_str += (\" \" * req_spacing)\n",
    "            escape_seq_count += 1\n",
    "    output_str += \"]\"\n",
    "    return output_str\n",
    "\n",
    "def create_new_cell_with_removal_features(df,\n",
    "                                          replace=True):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Creates a new cell block with a list of suggested features to remove.\n",
    "    \n",
    "    Args:\n",
    "        df:\n",
    "            Pandas DataFrame object\n",
    "            \n",
    "        replace:\n",
    "            Boolean to determine replacing the current cell.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get suggestions for removal\n",
    "    cell_content = __format_list_to_string(\"removal_features\",\n",
    "                                           suggest_removal_features(df))\n",
    "    # Add a sort of calling card of the function that created it\n",
    "    cell_content = f\"# create_new_cell_with_removal_features(df,replace={replace})\\n\" + cell_content\n",
    "    create_new_cell(cell_content,\n",
    "                    replace=replace)\n",
    "\n",
    "def create_new_cell_with_null_removal_features(df,\n",
    "                                               null_threshold=.25,\n",
    "                                               replace=True):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Creates a new cell block with a list of suggested features to remove based on nulls.\n",
    "    \n",
    "    Args:\n",
    "        df:\n",
    "            Pandas DataFrame object\n",
    "            \n",
    "        null_threshold:\n",
    "            Any features that contain x% percent of nulls are suggested.\n",
    "            \n",
    "        replace:\n",
    "            Boolean to determine replacing the current cell.\n",
    "    \"\"\"\n",
    "    \n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = df.isnull().sum() / len(df)\n",
    "\n",
    "    cell_content = __format_list_to_string(\"remove_null_features\",\n",
    "                                            mis_val_percent[mis_val_percent > null_threshold].index.to_list())\n",
    "    # Add a calling card of the function that created it\n",
    "    cell_content += f\"# create_new_cell_with_null_removal_features(df,null_threshold={null_threshold},replace={replace})\\n\"\n",
    "    create_new_cell(cell_content,\n",
    "                    replace=replace)\n",
    "\n",
    "def create_new_cell_with_feature_value_color_dict(df,\n",
    "                                                  df_features,\n",
    "                                                  value_limit=50,\n",
    "                                                  replace=True):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Creates a new cell block with a dict of suggested feature value colors.\n",
    "    \n",
    "    Args:\n",
    "        df:\n",
    "            Pandas DataFrame object\n",
    "        \n",
    "        df_features:\n",
    "            DataFrameTypes object.\n",
    "        \n",
    "        null_threshold:\n",
    "            Any features that contain x% percent of nulls are suggested.\n",
    "            \n",
    "        value_limit:\n",
    "            Limit the amount of feature_values until the system will ignore\n",
    "            the feature all together for dict generation.\n",
    "            \n",
    "        replace:\n",
    "            Boolean to determine replacing the current cell.\n",
    "    \"\"\"\n",
    "    feature_value_color_dict = create_color_dict_for_features(df,\n",
    "                                                              df_features,\n",
    "                                                              value_limit)\n",
    "    # Add a sort of calling card of the function that created it\n",
    "    cell_content = \"\"\n",
    "    cell_content += f\"# create_new_cell_with_feature_value_color_dict(df,df_features,value_limit={value_limit},replace={replace})\\n\"\n",
    "    cell_content += \"feature_value_color_dict=dict()\"\n",
    "    feature_count = 0\n",
    "    for feature_name, feature_value_color in feature_value_color_dict.items():\n",
    "        if feature_value_color_dict[feature_name].keys(): \n",
    "            cell_content += f\"\\nfeature_value_color_dict[\\\"{feature_name}\\\"] = dict()\"\n",
    "        else:\n",
    "            cell_content += f\"\\n\\n# The feature '{feature_name}' has to many values! Asserting assumption that you don't want to give colors to each!\"\n",
    "        \n",
    "        for feature_value, color in feature_value_color.items():\n",
    "\n",
    "            color = feature_value_color_dict[feature_name][feature_value]\n",
    "            \n",
    "            if feature_name in df_features.get_bool_features() or feature_name in df_features.get_categorical_features():\n",
    "                try:\n",
    "                    feature_value = int(float(feature_value))\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            if isinstance(feature_value,str):\n",
    "                feature_value = f\"\\\"{feature_value}\\\"\"\n",
    "            else:\n",
    "                feature_value = f\"{feature_value}\"\n",
    "            \n",
    "            if color is None:\n",
    "                cell_content += f\"\\nfeature_value_color_dict[\\\"{feature_name}\\\"][{feature_value}] = None\"\n",
    "            else:\n",
    "                cell_content += f\"\\nfeature_value_color_dict[\\\"{feature_name}\\\"][{feature_value}] = \\\"{color}\\\"\"\n",
    "        cell_content += \"\\n\"\n",
    "        \n",
    "    create_new_cell(cell_content,\n",
    "                    replace=replace)\n",
    "\n",
    "def create_new_cell_with_categorical_dict(df,\n",
    "                                          df_features,\n",
    "                                          value_limit=50,\n",
    "                                          replace=True):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Creates a new cell block with a dict of\n",
    "    \n",
    "    Args:\n",
    "        df:\n",
    "            Pandas DataFrame object\n",
    "\n",
    "        df_features:\n",
    "            DataFrameTypes object.\n",
    "\n",
    "        value_limit:\n",
    "            Limit the amount of feature_values until the system will ignore\n",
    "            the feature all together for dict generation.\n",
    "            \n",
    "        replace:\n",
    "            Boolean to determine replacing the current cell.\n",
    "    \"\"\"\n",
    "\n",
    "    cell_content = \"\"\n",
    "    cell_content += f\"# create_new_cell_with_categorical_dict(df,df_features,value_limit={value_limit},replace={replace})\\n\"\n",
    "    cell_content += \"categorical_value_dict = dict()\\n\"\n",
    "    \n",
    "    categorical_value_dict = dict()\n",
    "    for feature_name in df_features.get_categorical_features():\n",
    "        \n",
    "        # Find and sort feature values\n",
    "        feature_values = df[feature_name].value_counts(sort=False).index.to_list()\n",
    "        feature_values = [str(val) for val in feature_values]\n",
    "        feature_values.sort()\n",
    "        \n",
    "        # Create feature cat dict\n",
    "        cat_found = False\n",
    "        categorical_value_dict[feature_name] = dict()\n",
    "        for val in feature_values:\n",
    "            try:\n",
    "                categorical_value_dict[feature_name][int(val)] = \"\"\n",
    "                cat_found = True\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        # Delete feature name if no categories are found\n",
    "        if not cat_found:\n",
    "            del categorical_value_dict[feature_name]\n",
    "    \n",
    "    for feature_name,cat_val_dict in categorical_value_dict.items():\n",
    "        \n",
    "        if len(cat_val_dict.keys()) < value_limit:\n",
    "            cell_content += f\"categorical_value_dict[\\\"{feature_name}\\\"]=dict()\\n\"\n",
    "            for cat,val in cat_val_dict.items():\n",
    "\n",
    "                if isinstance(val,str):\n",
    "                    cell_content += f\"categorical_value_dict[\\\"{feature_name}\\\"][{cat}] = \\\"{val}\\\"\\n\"\n",
    "                else:\n",
    "                    cell_content += f\"categorical_value_dict[\\\"{feature_name}\\\"][{cat}] = {val}\\n\"\n",
    "        else:\n",
    "            cell_content += f\"\\n\\n# The feature '{feature_name}' has to many values! Asserting assumption that you don't want to give encode to each!\"\n",
    "\n",
    "        \n",
    "\n",
    "    create_new_cell(cell_content,\n",
    "                    replace=replace)\n",
    "    \n",
    "    \n",
    "\n",
    "def create_new_cell_with_value_representation(df,\n",
    "                                              df_features,\n",
    "                                              value_limit=50,\n",
    "                                              replace=True):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Creates a new cell block with a dict of suggested feature value colors.\n",
    "    \n",
    "    Args:\n",
    "        df:\n",
    "            Pandas DataFrame object\n",
    "\n",
    "        df_features:\n",
    "            DataFrameTypes object.\n",
    "\n",
    "        value_limit:\n",
    "            Limit the amount of feature_values until the system will ignore\n",
    "            the feature all together for dict generation.\n",
    "            \n",
    "        replace:\n",
    "            Boolean to determine replacing the current cell.\n",
    "    \"\"\"\n",
    "    feature_value_representation = dict()\n",
    "    for feature_name in df_features.get_string_features():\n",
    "        feature_value_representation[feature_name] = dict()\n",
    "        for val in df[feature_name].dropna().value_counts(sort=False).index.to_list():\n",
    "            if isinstance(val,str):\n",
    "                if len(val) == 0:\n",
    "                    continue\n",
    "                if len(val) <= 3 or val not in words.words():\n",
    "                    feature_value_representation[feature_name][val] = \"\"\n",
    "\n",
    "                if len(feature_value_representation[feature_name].keys()) >= 50:\n",
    "                    break\n",
    "\n",
    "        if not len(feature_value_representation[feature_name].keys()):\n",
    "            del feature_value_representation[feature_name]\n",
    "    cell_content = \"\"\n",
    "    cell_content += f\"# create_new_cell_with_value_representation(df,df_features,value_limit={value_limit},replace={replace})\\n\"\n",
    "    \n",
    "    cell_content += \"feature_value_representation = dict()\\n\"\n",
    "    for feature_name,val_repr_dict in feature_value_representation.items():\n",
    "        \n",
    "        if len(val_repr_dict.keys()) < value_limit:\n",
    "            cell_content += f\"feature_value_representation[\\\"{feature_name}\\\"] = dict()\\n\"\n",
    "            for val,reprs in val_repr_dict.items():\n",
    "\n",
    "                if isinstance(val,str):\n",
    "                    cell_content += f\"feature_value_representation[\\\"{feature_name}\\\"][\\\"{val}\\\"] = \"\n",
    "                else:\n",
    "                    cell_content += f\"feature_value_representation[\\\"{feature_name}\\\"][{val}] = \"\n",
    "                \n",
    "                if isinstance(reprs,str):\n",
    "                    cell_content += f\"\\\"{reprs}\\\"\\n\"\n",
    "                else:\n",
    "                    cell_content += f\"{reprs}\\n\"\n",
    "        else:\n",
    "            cell_content += f\"\\n\\n# The feature '{feature_name}' has to many values! Asserting assumption that you don't want to give representation to to each!\"\n",
    "        \n",
    "        cell_content += \"\\n\"\n",
    "    create_new_cell(cell_content,\n",
    "                    replace=replace)\n",
    "\n",
    "def create_new_cell_with_binned_features(df,\n",
    "                                         df_features,\n",
    "                                         bins=5,\n",
    "                                         replace=True):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Creates a new cell block with a list of suggested bins and labels for each feature.\n",
    "    \n",
    "    Args:\n",
    "        df:pd.Dataframe\n",
    "            Pandas DataFrame object.\n",
    "        \n",
    "        df_features:\n",
    "            DataFrameTypes object.\n",
    "            \n",
    "        bins:int\n",
    "            The amount of bins to give to apply to each feature\n",
    "            \n",
    "        replace:bool\n",
    "            Boolean to determine replacing the current cell.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add a sort of calling card of the function that created it\n",
    "    cell_content = f\"# create_new_cell_with_binned_features(df,df_features,bins={bins},replace={replace})\\n\"\n",
    "    \n",
    "    for feature_name in df_features.continuous_numerical_features():\n",
    "        bins,labels = auto_binning(df,\n",
    "                                   df_features,\n",
    "                                   feature_name,\n",
    "                                   bins=5)\n",
    "        cell_content += f\"feature_name = \\\"{feature_name}\\\"\\n\"\n",
    "        cell_content += __format_list_to_string(\"bins\",\n",
    "                                                bins)\n",
    "        cell_content += \"\\n\"\n",
    "        cell_content += __format_list_to_string(\"labels\",\n",
    "                                                labels)\n",
    "        \n",
    "        cell_content += f\"\\ndf_features.set_feature_binning(feature_name,\\n\"\n",
    "        cell_content += \"                                bins,\\n\"\n",
    "        cell_content += \"                                labels)\\n\"\n",
    "        cell_content += \"\\n\\n\"\n",
    "    \n",
    "    create_new_cell(cell_content,\n",
    "                    replace=replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Project Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"\"\n",
    "dataset_name = \"\"\n",
    "\n",
    "# -----\n",
    "inspect_data_project_dir = f\"{dataset_name}/Before Cleaning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----\n",
    "notebook_mode = True\n",
    "\n",
    "# -----\n",
    "display_value_counts = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'' does not exist: b''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c759efc5125d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m shape_df = pd.DataFrame.from_dict({'Rows': [df.shape[0]],\n\u001b[1;32m      3\u001b[0m                                    'Columns': [df.shape[1]]})\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eflow/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eflow/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eflow/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eflow/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eflow/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'' does not exist: b''"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(dataset_path)\n",
    "shape_df = pd.DataFrame.from_dict({'Rows': [df.shape[0]],\n",
    "                                   'Columns': [df.shape[1]]})\n",
    "display(shape_df)\n",
    "display(df.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove/Declare any unwanted features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When starting a new project uncomment the function to get suggestions and then run the cell again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_cell_with_removal_features(df,replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=removal_features,\n",
    "        inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_cell_with_null_removal_features(df,null_threshold=1,replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=remove_null_features,\n",
    "        inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gui tools for quick analysis dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great interface; pauses the program; comment on/off at free will.\n",
    "You will need to reset kernel after use more than likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandasgui import show as qt_display\n",
    "# qt_display(df)\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_ui(df,\n",
    "#          outfile_path='Piviot_Table_JS.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Any basic manipulation of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What I mean by this is say you want to represent a feature slightly different than it is currently displaying.\n",
    "Note: that whatever maniuplation you do here you should bring to each notebook's section of \"Any basic manipulation of features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skim through Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if display_value_counts:\n",
    "    for feature_name in df.columns:\n",
    "        print(f'******* Feature: {feature_name} *******')\n",
    "        print(f'Type: {df[feature_name].dtype}')\n",
    "        display(value_counts_table(df,\n",
    "                                   feature_name))\n",
    "        print(\"-------\" * 4 + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mark target feature; set to None if not needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning problems (Can be set to None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if target_feature:\n",
    "        df[target_feature]\n",
    "except KeyError:\n",
    "    raise KeyError(f\"The target feature \\'{target_feature}\\' was not found in the dataframe!\"\n",
    "                   + \" Please select a valid feature from the dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_feature:\n",
    "    print(f\"Target feature '{target_feature}'\")\n",
    "    print(\"----\" * 10)\n",
    "    target_amount = len(df[target_feature].dropna().value_counts().index)\n",
    "    value_count_df = value_counts_table(df,\n",
    "                                        target_feature)\n",
    "    if target_amount < 1:\n",
    "        display(value_count_df)\n",
    "    elif target_amount > 25:\n",
    "        display(value_count_df)\n",
    "        print(\"Value count is above 25 asserting that this is probably a continous data stream!\")\n",
    "    else:\n",
    "        # Change arg 'max_binary_threshold' to see changes in threshold\n",
    "        max_unbalanced_class_threshold, min_unbalanced_class_threshold = get_unbalanced_threshold(target_amount)\n",
    "        \n",
    "        print(f\"max_unbalanced_class_threshold = {max_unbalanced_class_threshold * 100:.3f}%\")\n",
    "        print(f\"min_unbalanced_class_threshold = {min_unbalanced_class_threshold * 100:.3f}%\")\n",
    "        display(value_count_df)\n",
    "        index = 0\n",
    "        for percentage in value_count_df[\"Percantage\"]:\n",
    "            percentage = float(percentage[:-1])/100\n",
    "            if percentage >= max_unbalanced_class_threshold or percentage <= min_unbalanced_class_threshold:\n",
    "                print(f\"The value '{value_count_df.index.values[index]}' is causing the target feature to be unbalanced.\\n\" +\n",
    "                      \"This could cause a model to not properly generalize itself.\")\n",
    "                print(\"---\" * 10 + \"\\n\")\n",
    "\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load/Init DataFrameTypes object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object is used to store an abstracted form of what a feature 'should be' rather than what the pandas dataframe object says it is. In this case we will be specifying all features correct types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment out/remove depending on how you want your design flow to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = DataFrameTypes(df,\n",
    "                             ignore_nulls=True,\n",
    "                             fix_numeric_features=True,\n",
    "                             fix_string_features=True,\n",
    "                             target_feature=target_feature,\n",
    "                             notebook_mode=notebook_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make any changes to 'df_features' that automated type assertions messed up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex: Sometimes df_features will think a feature is a category when it isn't. Move to proper types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df_features types:\")\n",
    "df_features.display_features(display_dataframes=True,\n",
    "                             notebook_mode=notebook_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.set_feature_to_bool(feature_name=[])\n",
    "df_features.set_feature_to_integer(feature_name=[])\n",
    "df_features.set_feature_to_float(feature_name=[])\n",
    "df_features.set_feature_to_string(feature_name=[])\n",
    "df_features.set_feature_to_datetime(feature_name=[])\n",
    "df_features.set_feature_to_categorical(feature_name=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df_features types:\")\n",
    "df_features.display_features(display_dataframes=True,\n",
    "                             notebook_mode=notebook_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataframe's types:\")\n",
    "data_types_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colors and palletes for features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove any unwanted values found or any unwanted features to be color coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_cell_with_feature_value_color_dict(df,df_features,value_limit=50,replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_widget = ColorLabelingWidget()\n",
    "cleaning_widget.run_widget(feature_value_color_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinitialize feature color dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_value_color_dict = cleaning_widget.get_feature_value_color_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_value_color_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.set_feature_colors(feature_value_color_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label categories if possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's considered good practice to label up your categories with proper labels for graphing/analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_cell_with_categorical_dict(df,df_features,value_limit=50,replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.set_encoder_for_features(df,\n",
    "                                     categorical_value_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Reprsentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good practice to describe our data as best as possible. Instead of values being abbreviation forms of their actual value.\n",
    "Ex: M = Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_cell_with_value_representation(df,df_features,value_limit=50,replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.set_feature_value_representation(feature_value_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bin any numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_cell_with_binned_features(df,df_features,bins=5,replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test encoding and value reprsentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoder = DataEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoder.apply_value_representation(df,\n",
    "                                        df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoder.decode_data(df,\n",
    "                         df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.display_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis of feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_analysis = FeatureAnalysis(df_features,\n",
    "                                   project_sub_dir=inspect_data_project_dir)\n",
    "feature_analysis.perform_analysis(df,\n",
    "                                  dataset_name= \"Full \" + dataset_name,\n",
    "                                  target_features=[df_features.target_feature()],\n",
    "                                  suppress_runtime_errors=False,\n",
    "                                  display_print=False,\n",
    "                                  display_visuals=False,\n",
    "                                  dataframe_snapshot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del feature_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Analysis of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_analysis = NullAnalysis(df_features,\n",
    "                             project_sub_dir=inspect_data_project_dir,\n",
    "                             notebook_mode=notebook_mode)\n",
    "\n",
    "null_analysis.perform_analysis(df,\n",
    "                               dataset_name=\"Full \" + dataset_name,\n",
    "                               null_features_only=True,\n",
    "                               display_visuals=True,\n",
    "                               display_print=False,\n",
    "                               dataframe_snapshot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_table = missing_values_table(df)\n",
    "display(missing_table)\n",
    "nan_features = missing_table[missing_table[\"% of Total Values\"] > 15].index.to_list()\n",
    "print(\"Above defined percentage:\")\n",
    "display(nan_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_analysis.feature_analysis_of_null_data(df,\n",
    "                                            \"Full \" + dataset_name,\n",
    "                                            target_features=[df_features.target_feature()],\n",
    "                                            display_visuals=False,\n",
    "                                            display_print=False,\n",
    "                                            save_file=True,\n",
    "                                            suppress_runtime_errors=True,\n",
    "                                            aggregate_target_feature=True,\n",
    "                                            extra_tables=True,\n",
    "                                            nan_features=nan_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del null_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a json file of df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_dir = create_dir_structure(os.getcwd(),\n",
    "                                   f\"/eflow Data/{dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.create_json_file_representation(created_dir,\n",
    "                                            \"df_features.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = DataFrameTypes()\n",
    "df_features.init_on_json_file(os.getcwd() + f\"/eflow Data/{dataset_name}/df_features.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.display_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_unconnected_pipeline_segments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test encoding and value reprsentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoder.make_values_bool(df,\n",
    "                              df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoder.revert_value_representation(df,\n",
    "                                         df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoder.encode_data(df,\n",
    "                         df_features,\n",
    "                         apply_value_representation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoder.decode_data(df,\n",
    "                         df_features,\n",
    "                         apply_value_representation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualtative_features = df_features.string_features() | df_features.categorical_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoder.make_dummies(df,\n",
    "                          df_features,\n",
    "                          qualtative_features=qualtative_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoder.revert_dummies(df,\n",
    "                            df_features,\n",
    "                            qualtative_features=qualtative_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
