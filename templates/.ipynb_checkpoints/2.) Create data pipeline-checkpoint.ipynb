{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the markdown blocks that say interaction required! The notebook should take care of the rest!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "from eflow.foundation import DataPipeline,DataFrameTypes\n",
    "from eflow.data_analysis import FeatureAnalysis, NullAnalysis\n",
    "from eflow.model_analysis import ClassificationAnalysis\n",
    "from eflow.data_pipeline_segments import FeatureTransformer, TypeFixer, DataEncoder, FeatureDataCleaner\n",
    "from eflow.utils.modeling_utils import optimize_model_grid\n",
    "from eflow.utils.eflow_utils import get_type_holder_from_pipeline, remove_unconnected_pipeline_segments\n",
    "from eflow.utils.math_utils import get_unbalanced_threshold\n",
    "from eflow.utils.sys_utils import create_dir_structure\n",
    "from eflow.utils.eflow_utils import create_color_dict_for_features\n",
    "from eflow.utils.pandas_utils import missing_values_table,data_types_table, value_counts_table, suggest_removal_features \n",
    "from eflow.widgets import ColorLabelingWidget\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.getipython import get_ipython\n",
    "import ipython_blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Additional add ons\n",
    "# !pip install pandasgui\n",
    "# !pip install pivottablejs\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juypter notebook generating cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note: Replace if set to True will remove all the contents of whatever cell it is called in. But it can be undone with a simple CMD + Z. ðŸ™‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: http://tinyurl.com/y6mghyzl\n",
    "def create_new_cell(contents,\n",
    "                    replace=False):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Creates a new jupyter cell.\n",
    "    \"\"\"\n",
    "    shell = get_ipython()\n",
    "    shell.set_next_input(contents,\n",
    "                         replace=replace)\n",
    "\n",
    "def __format_list_to_string(list_name,\n",
    "                            list_contents):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Converts a list to a string and adds newlines for formating.\n",
    "    \"\"\"\n",
    "    output_str = f\"{list_name} = [\"\n",
    "    escape_seq_count = 0\n",
    "    final_index = len(list_contents) - 1\n",
    "    req_spacing = len(output_str)\n",
    "\n",
    "    for i,element in enumerate(list_contents):\n",
    "        if i == final_index:\n",
    "            if isinstance(element,str):\n",
    "                output_str += f'\\\"{element}\\\"'\n",
    "            else:\n",
    "                output_str += f'{element}'\n",
    "        else:\n",
    "\n",
    "            if isinstance(element,str):\n",
    "                output_str += f'\\\"{element}\\\",'\n",
    "            else:\n",
    "                output_str += f'{element},'\n",
    "        \n",
    "        if len(output_str.split(\"\\n\")[escape_seq_count]) > 78:\n",
    "            output_str += \"\\n\"\n",
    "            output_str += (\" \" * req_spacing)\n",
    "            escape_seq_count += 1\n",
    "    output_str += \"]\"\n",
    "    return output_str\n",
    "\n",
    "def create_new_cell_with_removal_features(df,\n",
    "                                          replace=True):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Creates a new cell block with a list of suggested features to remove.\n",
    "    \n",
    "    Args:\n",
    "        df:\n",
    "            Pandas DataFrame object\n",
    "            \n",
    "        replace:\n",
    "            Boolean to determine replacing the current cell.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get suggestions for removal\n",
    "    cell_content = __format_list_to_string(\"removal_features\",\n",
    "                                           suggest_removal_features(df))\n",
    "    # Add a sort of calling card of the function that created it\n",
    "    cell_content = f\"# create_new_cell_with_removal_features(df,replace={replace})\\n\" + cell_content\n",
    "    create_new_cell(cell_content,\n",
    "                    replace=replace)\n",
    "\n",
    "def create_new_cell_with_null_removal_features(df,\n",
    "                                               null_threshold=.25,\n",
    "                                               replace=True):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Creates a new cell block with a list of suggested features to remove based on nulls.\n",
    "    \n",
    "    Args:\n",
    "        df:\n",
    "            Pandas DataFrame object\n",
    "            \n",
    "        null_threshold:\n",
    "            Any features that contain x% percent of nulls are suggested.\n",
    "            \n",
    "        replace:\n",
    "            Boolean to determine replacing the current cell.\n",
    "    \"\"\"\n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = df.isnull().sum() / len(df)\n",
    "    \n",
    "    cell_content = f\"# create_new_cell_with_null_removal_features(df,null_threshold={null_threshold},replace={replace})\\n\"\n",
    "    cell_content += __format_list_to_string(\"remove_null_features\",\n",
    "                                            mis_val_percent[mis_val_percent > null_threshold].index.to_list())\n",
    "    # Add a calling card of the function that created it\n",
    "    \n",
    "    create_new_cell(cell_content,\n",
    "                    replace=replace)\n",
    "\n",
    "def create_new_cell_with_feature_value_color_dict(df,\n",
    "                                                  df_features,\n",
    "                                                  value_limit=50,\n",
    "                                                  replace=True):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Creates a new cell block with a dict of suggested feature value colors.\n",
    "    \n",
    "    Args:\n",
    "        df:\n",
    "            Pandas DataFrame object\n",
    "        \n",
    "        df_features:\n",
    "            DataFrameTypes object.\n",
    "        \n",
    "        null_threshold:\n",
    "            Any features that contain x% percent of nulls are suggested.\n",
    "            \n",
    "        value_limit:\n",
    "            Limit the amount of feature_values until the system will ignore\n",
    "            the feature all together for dict generation.\n",
    "            \n",
    "        replace:\n",
    "            Boolean to determine replacing the current cell.\n",
    "    \"\"\"\n",
    "    feature_value_color_dict = create_color_dict_for_features(df,\n",
    "                                                              df_features,\n",
    "                                                              value_limit)\n",
    "    # Add a sort of calling card of the function that created it\n",
    "    cell_content = \"\"\n",
    "    cell_content += f\"# create_new_cell_with_feature_value_color_dict(df,df_features,value_limit={value_limit},replace={replace})\\n\"\n",
    "    cell_content += \"feature_value_color_dict=dict()\"\n",
    "    feature_count = 0\n",
    "    for feature_name, feature_value_color in feature_value_color_dict.items():\n",
    "        if feature_value_color_dict[feature_name].keys(): \n",
    "            cell_content += f\"\\nfeature_value_color_dict[\\\"{feature_name}\\\"] = dict()\"\n",
    "        else:\n",
    "            cell_content += f\"\\n\\n# The feature '{feature_name}' has to many values! Asserting assumption that you don't want to give colors to each!\"\n",
    "        \n",
    "        for feature_value, color in feature_value_color.items():\n",
    "\n",
    "            color = feature_value_color_dict[feature_name][feature_value]\n",
    "            \n",
    "            if feature_name in df_features.bool_features() or feature_name in df_features.categorical_features():\n",
    "                try:\n",
    "                    feature_value = int(float(feature_value))\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            if isinstance(feature_value,str):\n",
    "                feature_value = f\"\\\"{feature_value}\\\"\"\n",
    "            else:\n",
    "                feature_value = f\"{feature_value}\"\n",
    "            \n",
    "            if color is None:\n",
    "                cell_content += f\"\\nfeature_value_color_dict[\\\"{feature_name}\\\"][{feature_value}] = None\"\n",
    "            else:\n",
    "                cell_content += f\"\\nfeature_value_color_dict[\\\"{feature_name}\\\"][{feature_value}] = \\\"{color}\\\"\"\n",
    "        cell_content += \"\\n\"\n",
    "        \n",
    "    create_new_cell(cell_content,\n",
    "                    replace=replace)\n",
    "\n",
    "def create_new_cell_with_categorical_dict(df,\n",
    "                                          df_features,\n",
    "                                          value_limit=50,\n",
    "                                          replace=True):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Creates a new cell block with a dict of\n",
    "    \n",
    "    Args:\n",
    "        df:\n",
    "            Pandas DataFrame object\n",
    "\n",
    "        df_features:\n",
    "            DataFrameTypes object.\n",
    "\n",
    "        value_limit:\n",
    "            Limit the amount of feature_values until the system will ignore\n",
    "            the feature all together for dict generation.\n",
    "            \n",
    "        replace:\n",
    "            Boolean to determine replacing the current cell.\n",
    "    \"\"\"\n",
    "\n",
    "    cell_content = \"\"\n",
    "    cell_content += f\"# create_new_cell_with_categorical_dict(df,df_features,value_limit={value_limit},replace={replace})\\n\"\n",
    "    cell_content += \"categorical_value_dict = dict()\\n\"\n",
    "    \n",
    "    categorical_value_dict = dict()\n",
    "    for feature_name in df_features.categorical_features():\n",
    "        \n",
    "        # Find and sort feature values\n",
    "        feature_values = df[feature_name].value_counts(sort=False).index.to_list()\n",
    "        feature_values = [str(val) for val in feature_values]\n",
    "        feature_values.sort()\n",
    "        \n",
    "        # Create feature cat dict\n",
    "        cat_found = False\n",
    "        categorical_value_dict[feature_name] = dict()\n",
    "        for val in feature_values:\n",
    "            try:\n",
    "                categorical_value_dict[feature_name][int(val)] = \"\"\n",
    "                cat_found = True\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        # Delete feature name if no categories are found\n",
    "        if not cat_found:\n",
    "            del categorical_value_dict[feature_name]\n",
    "    \n",
    "    for feature_name,cat_val_dict in categorical_value_dict.items():\n",
    "        \n",
    "        if len(cat_val_dict.keys()) < value_limit:\n",
    "            cell_content += f\"categorical_value_dict[\\\"{feature_name}\\\"]=dict()\\n\"\n",
    "            for cat,val in cat_val_dict.items():\n",
    "\n",
    "                if isinstance(val,str):\n",
    "                    cell_content += f\"categorical_value_dict[\\\"{feature_name}\\\"][{cat}] = \\\"{val}\\\"\\n\"\n",
    "                else:\n",
    "                    cell_content += f\"categorical_value_dict[\\\"{feature_name}\\\"][{cat}] = {val}\\n\"\n",
    "        else:\n",
    "            cell_content += f\"\\n\\n# The feature '{feature_name}' has to many values! Asserting assumption that you don't want to give encode to each!\"\n",
    "\n",
    "        \n",
    "\n",
    "    create_new_cell(cell_content,\n",
    "                    replace=replace)\n",
    "    \n",
    "    \n",
    "\n",
    "def create_new_cell_with_value_representation(df,\n",
    "                                              df_features,\n",
    "                                              value_limit=50,\n",
    "                                              replace=True):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Creates a new cell block with a dict of suggested feature value colors.\n",
    "    \n",
    "    Args:\n",
    "        df:\n",
    "            Pandas DataFrame object\n",
    "\n",
    "        df_features:\n",
    "            DataFrameTypes object.\n",
    "\n",
    "        value_limit:\n",
    "            Limit the amount of feature_values until the system will ignore\n",
    "            the feature all together for dict generation.\n",
    "            \n",
    "        replace:\n",
    "            Boolean to determine replacing the current cell.\n",
    "    \"\"\"\n",
    "    feature_value_representation = dict()\n",
    "    for feature_name in df_features.string_features():\n",
    "        feature_value_representation[feature_name] = dict()\n",
    "        for val in df[feature_name].dropna().value_counts(sort=False).index.to_list():\n",
    "            if isinstance(val,str):\n",
    "                if len(val) == 0:\n",
    "                    continue\n",
    "                if len(val) <= 3 or val not in words.words():\n",
    "                    feature_value_representation[feature_name][val] = \"\"\n",
    "\n",
    "                if len(feature_value_representation[feature_name].keys()) >= 50:\n",
    "                    break\n",
    "\n",
    "        if not len(feature_value_representation[feature_name].keys()):\n",
    "            del feature_value_representation[feature_name]\n",
    "    cell_content = \"\"\n",
    "    cell_content += f\"# create_new_cell_with_value_representation(df,df_features,value_limit={value_limit},replace={replace})\\n\"\n",
    "    \n",
    "    cell_content += \"feature_value_representation = dict()\\n\"\n",
    "    for feature_name,val_repr_dict in feature_value_representation.items():\n",
    "        \n",
    "        if len(val_repr_dict.keys()) < value_limit:\n",
    "            cell_content += f\"feature_value_representation[\\\"{feature_name}\\\"] = dict()\\n\"\n",
    "            for val,reprs in val_repr_dict.items():\n",
    "\n",
    "                if isinstance(val,str):\n",
    "                    cell_content += f\"feature_value_representation[\\\"{feature_name}\\\"][\\\"{val}\\\"] = \"\n",
    "                else:\n",
    "                    cell_content += f\"feature_value_representation[\\\"{feature_name}\\\"][{val}] = \"\n",
    "                \n",
    "                if isinstance(reprs,str):\n",
    "                    cell_content += f\"\\\"{reprs}\\\"\\n\"\n",
    "                else:\n",
    "                    cell_content += f\"{reprs}\\n\"\n",
    "        else:\n",
    "            cell_content += f\"\\n\\n# The feature '{feature_name}' has to many values! Asserting assumption that you don't want to give representation to to each!\"\n",
    "        \n",
    "        cell_content += \"\\n\"\n",
    "    create_new_cell(cell_content,\n",
    "                    replace=replace)\n",
    "\n",
    "def create_new_cell_with_binned_features(df,\n",
    "                                         df_features,\n",
    "                                         bins=5,\n",
    "                                         replace=True):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Creates a new cell block with a list of suggested bins and labels for each feature.\n",
    "    \n",
    "    Args:\n",
    "        df:pd.Dataframe\n",
    "            Pandas DataFrame object.\n",
    "        \n",
    "        df_features:\n",
    "            DataFrameTypes object.\n",
    "            \n",
    "        bins:int\n",
    "            The amount of bins to give to apply to each feature\n",
    "            \n",
    "        replace:bool\n",
    "            Boolean to determine replacing the current cell.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add a sort of calling card of the function that created it\n",
    "    cell_content = f\"# create_new_cell_with_binned_features(df,df_features,bins={bins},replace={replace})\\n\"\n",
    "    \n",
    "    for feature_name in df_features.continuous_numerical_features():\n",
    "        bins,labels = auto_binning(df,\n",
    "                                   df_features,\n",
    "                                   feature_name,\n",
    "                                   bins=5)\n",
    "        print(bins)\n",
    "        cell_content += f\"feature_name = \\\"{feature_name}\\\"\\n\"\n",
    "        cell_content += __format_list_to_string(\"bins\",\n",
    "                                                bins)\n",
    "        cell_content += \"\\n\"\n",
    "        cell_content += __format_list_to_string(\"labels\",\n",
    "                                                labels)\n",
    "        \n",
    "        cell_content += f\"\\ndf_features.set_feature_binning(feature_name,\\n\"\n",
    "        cell_content += \"                                bins,\\n\"\n",
    "        cell_content += \"                                labels)\\n\"\n",
    "        cell_content += \"\\n\\n\"\n",
    "    \n",
    "    create_new_cell(cell_content,\n",
    "                    replace=replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Project Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"\"\n",
    "\n",
    "# -----\n",
    "dataset_name = \"\"\n",
    "pipeline_name = \"\"\n",
    "\n",
    "# -----\n",
    "\n",
    "\n",
    "# -----\n",
    "notebook_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean out segment space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_unconnected_pipeline_segments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path)\n",
    "shape_df = pd.DataFrame.from_dict({'Rows': [df.shape[0]],\n",
    "                                   'Columns': [df.shape[1]]})\n",
    "display(shape_df)\n",
    "display(df.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and init df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option: 1\n",
    "# df_features = get_type_holder_from_pipeline(pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option: 2\n",
    "df_features = DataFrameTypes()\n",
    "df_features.init_on_json_file(os.getcwd() + f\"/eflow Data/{dataset_name}/df_features.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.display_features(display_dataframes=True,\n",
    "                             notebook_mode=notebook_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Any extra processing before eflow DataPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup pipeline structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipe = DataPipeline(pipeline_name,\n",
    "                         df,\n",
    "                         df_features,\n",
    "                         remove_past_contents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Unwanted Columns due to illogical nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any features that have to many nulls/we can't or shouldn't perform any special logic to determine the closest or actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_cell_with_null_removal_features(df,null_threshold=0.25,replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add to main pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(remove_null_features):\n",
    "    feature_transformer = FeatureTransformer()\n",
    "    feature_transformer.remove_features(df,\n",
    "                                        df_features,\n",
    "                                        remove_null_features)\n",
    "    main_pipe.add(\"Remove unresolvable null features\",\n",
    "                  feature_transformer)\n",
    "\n",
    "    del feature_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_table = missing_values_table(df)\n",
    "display(missing_table)\n",
    "nan_features = missing_table.index.to_list()\n",
    "nan_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner = FeatureDataCleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner.run_widget(df,\n",
    "                        df_features,\n",
    "                        nan_feature_names=df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError(\"Interact with widget before continuing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner.perform_saved_widget_input(df,\n",
    "                                        df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_table = missing_values_table(df)\n",
    "display(missing_table)\n",
    "remaing_nan_features = missing_table.index.to_list()\n",
    "remaing_nan_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipe.add(\"Cleaning features with methods that only apply to that one feature.\",\n",
    "              data_cleaner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoder = DataEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoder.apply_value_representation(df,\n",
    "                                        df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualtative_features = df_features.string_features() | df_features.categorical_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoder.make_dummies(df,\n",
    "                          df_features,\n",
    "                          qualtative_features=qualtative_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.display_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoder.make_values_bool(df,\n",
    "                              df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipe.add(\"Ensure values are in proper form; convert proper values to dummies!\",\n",
    "              data_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if the pipeline structure works on samples of the data and the entire set of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_tmp_df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [1,main_tmp_df.shape[0],5,15,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in sizes:\n",
    "    tmp_df_features = DataFrameTypes()\n",
    "    tmp_df_features.init_on_json_file(os.getcwd() + f\"/eflow Data/{dataset_name}/df_features.json\")\n",
    "    tmp_df = main_tmp_df[0:size]\n",
    "    failure_found = False\n",
    "    \n",
    "    main_pipe.perform_pipeline(tmp_df,\n",
    "                               tmp_df_features)\n",
    "    \n",
    "    print(f\"size of test data: {size}\")\n",
    "    \n",
    "    if df_features == tmp_df_features:\n",
    "        print(\"df_features PASSED TEST! Properly changed in the pipeline!\")\n",
    "    else:\n",
    "        print(\"df_features FAILED TEST! Didn't properly change in the pipeline\")\n",
    "        failure_found = True\n",
    "\n",
    "    if set(df.columns) == set(tmp_df.columns):\n",
    "        print(\"Field name check PASSED TEST! Field names were as expected.\")\n",
    "    else:\n",
    "        print(\"Field name check FAILED TEST! Field names did differ from expected.\")\n",
    "        failure_found = True\n",
    "        \n",
    "    if failure_found:\n",
    "        print(\"tmp_df\")\n",
    "        display(tmp_df)\n",
    "        print()\n",
    "        print(\"df\")\n",
    "        display(df[0:size])\n",
    "\n",
    "    print(\"***\" * 10)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.display_features()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
