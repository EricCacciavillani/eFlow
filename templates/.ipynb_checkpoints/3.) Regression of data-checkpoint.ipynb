{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the markdown blocks that say interaction required! The notebook should take care of the rest!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "from eflow.foundation import DataPipeline,DataFrameTypes\n",
    "from eflow.model_analysis import RegressionAnalysis\n",
    "from eflow.utils.modeling_utils import optimize_model_grid\n",
    "from eflow.utils.eflow_utils import get_type_holder_from_pipeline, remove_unconnected_pipeline_segments\n",
    "from eflow.utils.pandas_utils import data_types_table\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import pickle\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Additional add ons\n",
    "# !pip install pandasgui\n",
    "# !pip install pivottablejs\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Project Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"\"\n",
    "\n",
    "# -----\n",
    "dataset_name = \"\"\n",
    "pipeline_name = \"\"\n",
    "\n",
    "# -----\n",
    "\n",
    "\n",
    "# -----\n",
    "notebook_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean out segment space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_unconnected_pipeline_segments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path)\n",
    "shape_df = pd.DataFrame.from_dict({'Rows': [df.shape[0]],\n",
    "                                   'Columns': [df.shape[1]]})\n",
    "display(shape_df)\n",
    "display(df.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and init df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option: 1\n",
    "# df_features = get_type_holder_from_pipeline(pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option: 2\n",
    "df_features = DataFrameTypes()\n",
    "df_features.init_on_json_file(os.getcwd() + f\"/eflow Data/{dataset_name}/df_features.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.display_features(display_dataframes=True,\n",
    "                             notebook_mode=notebook_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Any extra processing before eflow DataPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup pipeline structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipe = DataPipeline(pipeline_name,\n",
    "                         df,\n",
    "                         df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipe.perform_pipeline(df,\n",
    "                           df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate out data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=df_features.target_feature()).values\n",
    "y = df[df_features.target_feature()].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=517,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_order = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Models and view results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best parameters for model\n",
    "param_grid = {\n",
    "    \"max_depth\": list(range(1, 10)),\n",
    "    'criterion': [\"mse\", \"friedman_mse\", \"mae\"]\n",
    "}\n",
    "\n",
    "model, best_params = optimize_model_grid(\n",
    "    model=DecisionTreeRegressor(),\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"r2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = repr(model).split(\"(\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_analysis = RegressionAnalysis(dataset_name=dataset_name,\n",
    "                                    model=model,\n",
    "                                    model_name=model_name,\n",
    "                                    feature_order=feature_order,\n",
    "                                    target_feature=\"Age\",\n",
    "                                    pred_funcs_dict={\"Predict function\":model.predict},\n",
    "                                    notebook_mode=notebook_mode,\n",
    "                                    df_features=df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_analysis.perform_analysis(X=X_train,\n",
    "                                y=y_train,\n",
    "                                dataset_name=\"Train Data\",\n",
    "                                regression_error_analysis=True,\n",
    "                                regression_correct_analysis=True,\n",
    "                                display_visuals=False,\n",
    "                                mse_score=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred_name in model_analysis.get_predictions_names():\n",
    "    for mse_score in [.2]:\n",
    "        print(f\"Prediction name: {pred_name} with mse_score greater than {mse_score}\")\n",
    "        infile = open(model_analysis.folder_path + \"Train Data\" + f\"/{pred_name}/MSE score greater than {mse_score}/Train Data/_Extras/Statistics/Stat methods of features dataframes.pkl\",'rb')\n",
    "        stat_methods_dict = pickle.load(infile)\n",
    "        infile.close()\n",
    "\n",
    "        for stats_method in stat_methods_dict.keys():\n",
    "            print(stats_method)\n",
    "            display(stat_methods_dict[stats_method].round(6))\n",
    "            all_feature_relationship = set()\n",
    "            for feature_relationship in stat_methods_dict[stats_method][:10].index.to_list():\n",
    "                for feature in feature_relationship.split(\" compared to \"):\n",
    "                    all_feature_relationship.add(feature)\n",
    "            print(all_feature_relationship)\n",
    "            print(\"-----\" * 12 + \"\\n\\n\")\n",
    "\n",
    "        del stat_methods_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_analysis.perform_analysis(X=X_test,\n",
    "                                y=y_test,\n",
    "                                dataset_name=\"Test Data\",\n",
    "                                regression_error_analysis=True,\n",
    "                                regression_correct_analysis=True,\n",
    "                                display_visuals=False,\n",
    "                                mse_score=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred_name in model_analysis.get_predictions_names():\n",
    "    for mse_score in [.2]:\n",
    "        print(f\"Prediction name: {pred_name} with mse_score less than {mse_score}\")\n",
    "        infile = open(model_analysis.folder_path + \"Test Data\" + f\"/{pred_name}/MSE score less than {mse_score}/Test Data/_Extras/Statistics/Stat methods of features dataframes.pkl\",'rb')\n",
    "        stat_methods_dict = pickle.load(infile)\n",
    "        infile.close()\n",
    "\n",
    "        for stats_method in stat_methods_dict.keys():\n",
    "            print(stats_method)\n",
    "            display(stat_methods_dict[stats_method].round(6))\n",
    "            all_feature_relationship = set()\n",
    "            for feature_relationship in stat_methods_dict[stats_method][:10].index.to_list():\n",
    "                for feature in feature_relationship.split(\" compared to \"):\n",
    "                    all_feature_relationship.add(feature)\n",
    "            print(all_feature_relationship)\n",
    "            print(\"-----\" * 12 + \"\\n\\n\")\n",
    "\n",
    "        del stat_methods_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
