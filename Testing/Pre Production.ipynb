{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import ipython_blocking\n",
    "from pivottablejs import pivot_ui\n",
    "import scikitplot as skplt\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from eflow import DataFrameTypes\n",
    "from eflow.analysis import DataAnalysis\n",
    "from eflow.pipeline_segments import DataCleaner\n",
    "from eflow.analysis import MissingDataAnalysis\n",
    "from eflow.utils.pandas_utils import data_types_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [1, 5], 2: [1, 2], 3: [1, 2, 5], 4: [1, 2], 6: [5], 7: [5]}\n"
     ]
    }
   ],
   "source": [
    "def revdict(d):\n",
    "    r = {}\n",
    "    for k in d:\n",
    "        for v in d[k]:\n",
    "            if v not in r:\n",
    "                r[v] = [k]\n",
    "            else:\n",
    "                r[v].append(k)\n",
    "    return r\n",
    "d={1:[1,2,3,4],2:[2,3,4],5:[1,3,6,7]}\n",
    "a = revdict(d)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be sure to run the following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Worflow Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (This should be the only place you should have to declare anything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"Datasets/titanic_train.csv\"\n",
    "target_column = \"Survived\"\n",
    "parent_project_name = \"Pre processing\"\n",
    "prediction_method = \"Classification\"\n",
    "notebook_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(dataset_path)\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Types</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Features</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Data Types\n",
       "Features              \n",
       "Age            float64\n",
       "Fare           float64\n",
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Ticket          object\n",
       "Cabin           object\n",
       "Embarked        object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_types_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction tool for dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"Piviot_Table_JS.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a1b672780>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_ui(df,\n",
    "         outfile_path='Piviot_Table_JS.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating graph for null dendrogram graph...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-668ff2e66714>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m missing_data_analysis.plot_null_dendrogram_graph(tester,\n\u001b[1;32m      7\u001b[0m                                                  \"All Data\")\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "missing_data_analysis = MissingDataAnalysis(sub_dir=parent_project_name)\n",
    "# missing_data_analysis.perform_analysis(df.head(42),\n",
    "#                                        \"All Data\")\n",
    "tester = copy.deepcopy(df)\n",
    "missing_data_analysis.plot_null_dendrogram_graph(tester,\n",
    "                                                 \"All Data\")\n",
    "raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = widgets.SelectMultiple(\n",
    "#     options=['Apples', 'Oranges', 'Pears'],\n",
    "#     value=['Oranges'],\n",
    "#     #rows=10,\n",
    "#     description='Fruits',\n",
    "#     disabled=False\n",
    "# )\n",
    "# del w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = str(u\"\\u2192\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Un-Wanted Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do not remove nans yet, let the datacleaner do it's job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Name\",\n",
    "                 \"Ticket\",\n",
    "                 \"PassengerId\"],\n",
    "        inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "dt = parser.parse(\"Aug 28 1999 12:00AM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date_test\"] = [\"2019-01-02\" for _ in range(0,df.shape[0])]\n",
    "df[\"Date_test\"][0] = np.nan\n",
    "# df[\"Date_test\"] = [parser.parse(val)for val in df[\"Date_test\"].value_counts().keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Feature manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change cabin column to have the level on the ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cabin\"] = df[\"Cabin\"].str.replace(r'\\d+', '').str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Feature Data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make given data type changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Pclass\"] = df[\"Pclass\"].replace(1, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final look at data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up DataFrameTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = DataFrameTypes(df,\n",
    "                             target_column=target_column,\n",
    "                             ignore_nulls=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skim through Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col not in df_features.get_float_features() and len(np.unique(df[col].dropna().values)) <= 12:\n",
    "        display(df[col].value_counts())\n",
    "        print(\"***\" * 4 + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform quick analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_obj = DataAnalysis(df,\n",
    "                            df_features,\n",
    "                            project_name=f'{parent_project_name}/General Analysis (Before Cleaning)',\n",
    "                            missing_data_visuals=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner = DataCleaner(df,\n",
    "                           project_name=f'{parent_project_name}/Data Cleaning',\n",
    "                           missing_data_visuals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner.data_cleaning_widget(df,\n",
    "                                  df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner.get_last_saved_json_file_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner.data_cleaning_with_json_file(df,\n",
    "                                          data_cleaner.get_last_saved_json_file_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from impyute.imputation.cs import mice\n",
    "\n",
    "a = df[\"Age\"].tolist()\n",
    "# start the MICE training\n",
    "imputed_training=mice(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datawig\n",
    "\n",
    "df_train, df_test = datawig.utils.random_split(df)\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer = datawig.SimpleImputer(\n",
    "    input_columns=['Survived', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Fare', 'Cabin','Embarked'], # column(s) containing information about the column we want to impute\n",
    "    output_column= 'Age', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer.fit(train_df=df, num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_training=mice(df[df_features.get_numerical_features()].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datawig\n",
    "# !pip install opencv-python\n",
    "# !pip install Pillow\n",
    "# !pip install tesserocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "df[\"Cabin\"] = df[\"Cabin\"].fillna(\"A\")\n",
    "test = df.drop(columns=[\"Date_test\", \"Embarked\"]).dropna()\n",
    "\n",
    "test[\"Cabin\"] = df[\"Cabin\"] == \"B\"\n",
    "test[\"Sex\"] = df[\"Sex\"] == \"male\"\n",
    "test[target_column] = [random.randint(0, 10) for _ in range(0,test.shape[0])]\n",
    "print(len(test[target_column]))\n",
    "\n",
    "y = test[target_column].values\n",
    "X = test.values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "df_features = DataFrameTypes(test,\n",
    "                             target_column=target_column,\n",
    "                             ignore_nulls=True) \n",
    "df_features.get_all_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=517, stratify=y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from eflow.modeling import optimize_model_grid\n",
    "# Find best parameters for model\n",
    "param_grid = {\n",
    "    \"max_depth\": list(range(2, 3)),\n",
    "    \"min_samples_leaf\": list(range(80, 130, 5)),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "#     \"n_splits\": [20, 30]\n",
    "}\n",
    "\n",
    "model, best_params = optimize_model_grid(\n",
    "    model=DecisionTreeClassifier(),\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    param_grid=param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eflow._hidden.Objects.enum import enum\n",
    "from eflow.utils.sys_utils import create_plt_png, convert_to_filename, \\\n",
    "    df_to_image, write_object_text_to_file, get_unique_directory_path, \\\n",
    "    pickle_object_to_file\n",
    "from eflow._hidden.Objects.FileOutput import *\n",
    "from eflow._hidden.CustomExc import *\n",
    "from eflow.analysis import DataAnalysis\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "import scikitplot as skplt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import copy\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ClassificationAnalysis(FileOutput):\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 model_name,\n",
    "                 pred_funcs_dict,\n",
    "                 sample_data,\n",
    "                 project_name=\"Classification analysis_objects\",\n",
    "                 overwrite_full_path=None,\n",
    "                 notebook_mode=True,\n",
    "                 target_classes=None,\n",
    "                 df_features=None,\n",
    "                 columns=[],\n",
    "                 save_model=True):\n",
    "        \"\"\"\n",
    "        model:\n",
    "            A fitted supervised machine learning model.\n",
    "\n",
    "        model_name:\n",
    "            The name of the model in string form.\n",
    "\n",
    "        pred_funcs_dict:\n",
    "            A dict of the name of the function and the function defintion for the\n",
    "            model prediction methods.\n",
    "            (Can handle either a return of probabilities or a singile value.)\n",
    "            Init Example:\n",
    "            pred_funcs = dict()\n",
    "            pred_funcs[\"Predictions\"] = model.predict\n",
    "            pred_funcs[\"Probabilities\"] = model.probas\n",
    "         \n",
    "        sample_data:\n",
    "            Given data to then pass into our prediction functions to get a\n",
    "            resultant to get the classification prediction 'type'. \n",
    "\n",
    "        project_name:\n",
    "            Creates a parent or \"project\" folder in which all sub-directories\n",
    "            will be inner nested.\n",
    "\n",
    "        overwrite_full_path:\n",
    "            Overwrites the path to the parent folder.\n",
    "\n",
    "        notebook_mode:\n",
    "            If in a python notebook display in the notebook.\n",
    "\n",
    "        target_classes:\n",
    "            Specfied list/np.array of targeted classes the model predicts. If set to\n",
    "            none then it will attempt to pull from the sklearn's default attribute\n",
    "            '.classes_'.\n",
    "\n",
    "        df_features:\n",
    "            DataFrameTypeHolder object. If initalized we can run correct/error\n",
    "            analysis on the dataframe. Will save object in a pickle file and provided columns\n",
    "            if initalized and df_features is not initalized.\n",
    "\n",
    "        columns:\n",
    "            Will overwrite over df_features (DataFrameTypeHolder) regardless \n",
    "            of whether or not df_features is init.\n",
    "            \n",
    "        Returns/Desc:\n",
    "            Evaluates the given model based on the prediction functions pased to it.\n",
    "            Saves the model and other various graphs/dataframes for evaluation.\n",
    "        \"\"\"\n",
    "\n",
    "        # Init any parent objects\n",
    "        FileOutput.__init__(self,\n",
    "                            f'{project_name}/{model_name}',\n",
    "                            overwrite_full_path)\n",
    "\n",
    "        # Init objects without pass by refrence\n",
    "        self.__model = copy.deepcopy(model)\n",
    "        self.__model_name = copy.deepcopy(model_name)\n",
    "        self.__notebook_mode = copy.deepcopy(notebook_mode)\n",
    "        self.__target_values = copy.deepcopy(target_classes)\n",
    "        self.__df_features = copy.deepcopy(df_features)\n",
    "        self.__pred_funcs_dict = copy.deepcopy(pred_funcs_dict)\n",
    "        self.__pred_funcs_types = dict()\n",
    "\n",
    "        # Init on sklearns default target classes attribute\n",
    "        if not self.__target_values:\n",
    "            self.__target_values = copy.deepcopy(model.classes_)\n",
    "        # ---\n",
    "        if len(self.__target_values) != 2:\n",
    "            self.__binary_classifcation = False\n",
    "        else:\n",
    "            self.__binary_classifcation = True\n",
    "\n",
    "        # Save machine learning model\n",
    "        if save_model:\n",
    "            pickle_object_to_file(self.__model,\n",
    "                                  self.get_output_folder(),\n",
    "                                  f'{self.__model_name}')\n",
    "\n",
    "        # ---\n",
    "        check_create_dir_structure(self.get_output_folder(),\n",
    "                                   \"Extras\")\n",
    "        # Save predicted classes\n",
    "        write_object_text_to_file(self.__target_values,\n",
    "                                  self.get_output_folder() + \"Extras\",\n",
    "                                  \"_Classes\")\n",
    "\n",
    "        # Save features and or df_features object\n",
    "        if columns or df_features:\n",
    "            if columns:\n",
    "                write_object_text_to_file(columns,\n",
    "                                          self.get_output_folder() + \"Extras\",\n",
    "                                          \"_Features\")\n",
    "            else:\n",
    "                write_object_text_to_file(df_features.get_all_features(),\n",
    "                                          self.get_output_folder() + \"Extras\",\n",
    "                                          \"_Features\")\n",
    "                pickle_object_to_file(self.__model,\n",
    "                                      self.get_output_folder() + \"Extras\",\n",
    "                                      \"_df_features\")\n",
    "\n",
    "        # Find the 'type' of each prediction. Probabilities or Predictions\n",
    "        if self.__pred_funcs_dict:\n",
    "            for pred_name, pred_func in self.__pred_funcs_dict.items():\n",
    "                model_output = pred_func(\n",
    "                    np.reshape(sample_data[0],\n",
    "                               (-1, sample_data.shape[1])))[0]\n",
    "\n",
    "                # Confidence / Probability (Continuous output)\n",
    "                if isinstance(model_output, list) or isinstance(model_output,\n",
    "                                                                np.ndarray):\n",
    "                    self.__pred_funcs_types[pred_name] = \"Probabilities\"\n",
    "\n",
    "                    # Classification (Discrete output)\n",
    "                else:\n",
    "                    self.__pred_funcs_types[pred_name] = \"Predictions\"\n",
    "        else:\n",
    "            raise RequiresPredictionMethods\n",
    "\n",
    "    def __get_model_prediction(self,\n",
    "                               pred_name,\n",
    "                               X,\n",
    "                               thresholds=None):\n",
    "        \"\"\"\n",
    "        X:\n",
    "            Feature matrix.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        Returns/Desc:\n",
    "            Returns back a predicted value based for a given matrix.\n",
    "            Handles prediction function 'types' Predictions and Probabilities.\n",
    "            Helps streamline the entire process of evaluating classes.\n",
    "        \"\"\"\n",
    "        # DEBUG_MARKER\n",
    "\n",
    "        # Must be a prediction function\n",
    "        if self.__pred_funcs_types[pred_name] == \"Predictions\":\n",
    "            return self.__pred_funcs_dict[pred_name](X)\n",
    "\n",
    "        elif self.__pred_funcs_types[pred_name] == \"Probabilities\":\n",
    "            \n",
    "            # Validate probabilities\n",
    "            if thresholds:\n",
    "                if isinstance(thresholds, list) or \\\n",
    "                        isinstance(thresholds, np.ndarray):\n",
    "                    if len(thresholds) != len(self.__target_values):\n",
    "                        raise ThresholdLength\n",
    "                else:\n",
    "                    raise ThresholdType\n",
    "\n",
    "            model_output = self.__get_model_probas(pred_name,\n",
    "                                                   X)\n",
    "            if not thresholds:\n",
    "                return np.asarray([self.__target_values[np.argmax(proba)]\n",
    "                                   for proba in model_output])\n",
    "                \n",
    "            \n",
    "            bool_matrix_thresholds = model_output < thresholds\n",
    "            \n",
    "            prob_passed_matrix = np.asarray([\n",
    "                np.asarray([model_output[i][0] if passed else float(\"-inf\") \n",
    "                            for i,passed in enumerate(bool_vector)])\n",
    "                for bool_vector in bool_matrix_thresholds])            \n",
    "\n",
    "            model_predictions = np.asarray([self.__target_values[np.argmax(proba_vector)]\n",
    "                                            if sum(proba_vector != float(\"-inf\")) > 0 \n",
    "                                            else self.__target_values[np.argmax(model_output)]\n",
    "                                            for proba_vector in prob_passed_matrix])\n",
    "            return model_predictions\n",
    "        else:\n",
    "            raise UnknownModelOutputType\n",
    "\n",
    "    def __get_model_probas(self,\n",
    "                           pred_name,\n",
    "                           X):\n",
    "        \"\"\"\n",
    "        X:\n",
    "            Feature matrix.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        Returns/Desc:\n",
    "            Returns back a series of values between 0-1 to represent it's confidence.\n",
    "            Invokes an error if the prediction function call is anything but a Probabilities\n",
    "            call.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.__pred_funcs_types[pred_name] == \"Probabilities\":\n",
    "            model_output = self.__pred_funcs_dict[pred_name](X)\n",
    "\n",
    "            # ---\n",
    "            if isinstance(model_output, list):\n",
    "                model_output = np.asarray(model_output)\n",
    "\n",
    "            return model_output\n",
    "        else:\n",
    "            raise ProbasNotPossible\n",
    "\n",
    "    def __create_sub_dir_with_thresholds(self,\n",
    "                                         pred_name,\n",
    "                                         dataset_name,\n",
    "                                         thresholds):\n",
    "        \"\"\"\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The passed in dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        Returns/Desc:\n",
    "            Looking at the root of the starting directory and looking at each\n",
    "            '_Thresholds.txt' file to determine if the files can be outputed\n",
    "            to that directory. The content of the file must match the content\n",
    "            of the list/numpy array 'thresholds'.\n",
    "        \"\"\"\n",
    "        sub_dir = f'{dataset_name}/{pred_name}'\n",
    "\n",
    "        # Only generate extra folder structure if function type is Probabilities\n",
    "        if self.__pred_funcs_types[pred_name] == \"Probabilities\":\n",
    "\n",
    "            # ------\n",
    "            if not thresholds:\n",
    "                sub_dir = f'{sub_dir}/No Thresholds'\n",
    "            else:\n",
    "                i = 0\n",
    "                sub_dir = f'{sub_dir}/Thresholds'\n",
    "                tmp_sub_dir = copy.deepcopy(sub_dir)\n",
    "                while True:\n",
    "                    threshold_dir = self.get_output_folder()\n",
    "                    if i > 0:\n",
    "                        tmp_sub_dir = (sub_dir + f' {i}')\n",
    "                    threshold_dir += tmp_sub_dir\n",
    "\n",
    "                    # If file exists with the same thresholds; than use this directory\n",
    "                    if os.path.exists(threshold_dir):\n",
    "                        if self.__compare_thresholds_to_saved_thresholds(\n",
    "                                threshold_dir,\n",
    "                                thresholds):\n",
    "                            sub_dir = tmp_sub_dir\n",
    "                            break\n",
    "\n",
    "                    # Create new directory\n",
    "                    else:\n",
    "                        os.makedirs(threshold_dir)\n",
    "                        write_object_text_to_file(thresholds,\n",
    "                                                  threshold_dir,\n",
    "                                                  \"_Thresholds\")\n",
    "                        sub_dir = tmp_sub_dir\n",
    "                        break\n",
    "\n",
    "                    # Iterate for directory name change\n",
    "                    i += 1\n",
    "\n",
    "        return sub_dir\n",
    "\n",
    "    def __compare_thresholds_to_saved_thresholds(self,\n",
    "                                                 directory_pth,\n",
    "                                                 thresholds):\n",
    "        \"\"\"\n",
    "        directory_pth:\n",
    "            Path to the given folder where the \"_Thresholds.txt\"\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        Returns/Desc:\n",
    "            Compare the thresholds object to the text file; returns true if\n",
    "            the file exists and the object's value matches up.\n",
    "        \"\"\"\n",
    "\n",
    "        file_directory = correct_directory_path(directory_pth)\n",
    "\n",
    "        if os.path.exists(file_directory):\n",
    "\n",
    "            # Extract file contents and convert to a list object\n",
    "            file = open(file_directory + \"_Thresholds.txt\", \"r\")\n",
    "            line = file.read()\n",
    "            converted_list = line.split(\"=\")[-1].strip().strip('][').split(\n",
    "                ', ')\n",
    "            converted_list = [float(val) for val in converted_list]\n",
    "            file.close()\n",
    "\n",
    "            if thresholds == converted_list:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def peform_analysis(self,\n",
    "                        X,\n",
    "                        y,\n",
    "                        dataset_name,\n",
    "                        thresholds_matrix=None,\n",
    "                        figsize=(10, 8),\n",
    "                        normalize_confusion_matrix=True,\n",
    "                        ignore_metrics=[],\n",
    "                        custom_metrics=dict(),\n",
    "                        average_scoring=[\"micro\",\n",
    "                                         \"macro\",\n",
    "                                         \"weighted\"],\n",
    "                        display_analysis_graphs=False):\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds_matrix:\n",
    "            List of list/Matrix of thresholds\n",
    "\n",
    "            each thresholds:\n",
    "                If the model outputs a probability list/numpy array then we apply\n",
    "                thresholds to the ouput of the model.\n",
    "                For classification only; will not affect the direct output of\n",
    "                the probabilities.\n",
    "\n",
    "        figsize:\n",
    "            Plot's dimension's.\n",
    "\n",
    "        normalize_confusion_matrix:\n",
    "            Normalize the confusion matrix buckets.\n",
    "\n",
    "        ignore_metrics:\n",
    "            Specify set metrics to ignore. (F1-Score, Accuracy etc).\n",
    "\n",
    "        ignore_metrics:\n",
    "            Specify the default metrics to not apply to the classification\n",
    "            analysis.\n",
    "                * Precision\n",
    "                * MCC\n",
    "                * Recall\n",
    "                * F1-Score\n",
    "                * Accuracy\n",
    "\n",
    "        custom_metrics:\n",
    "            Pass the name of metric(s) and the function definition(s) in a\n",
    "            dictionary.\n",
    "\n",
    "        average_scoring:\n",
    "            Determines the type of averaging performed on the data.\n",
    "\n",
    "        display_analysis_graphs:\n",
    "            Controls visual display of error error analysis if it is able to run.\n",
    "\n",
    "        Returns/Desc:\n",
    "            Performs all classification functionality with the provided feature\n",
    "            data and target data.\n",
    "                * plot_precision_recall_curve\n",
    "                * classification_evaluation\n",
    "                * plot_confusion_matrix\n",
    "        \"\"\"\n",
    "        if isinstance(thresholds_matrix, np.ndarray):\n",
    "            thresholds_matrix = thresholds_matrix.tolist()\n",
    "\n",
    "        if not thresholds_matrix:\n",
    "            thresholds_matrix = list()\n",
    "\n",
    "        if isinstance(thresholds_matrix, list) and not isinstance(\n",
    "                thresholds_matrix[0], list):\n",
    "            thresholds_matrix = list(thresholds_matrix)\n",
    "        \n",
    "        \n",
    "        if None not in thresholds_matrix:\n",
    "            thresholds_matrix.append(None)\n",
    "\n",
    "        print(\"\\n\\n\" + \"---\" * 10 + f'{dataset_name}' + \"---\" * 10)\n",
    "\n",
    "        for pred_name, pred_type in self.__pred_funcs_types.items():\n",
    "            print(f\"Now running classification on {pred_name}\", end = '')\n",
    "            print(\"hit\")\n",
    "            for thresholds in thresholds_matrix:\n",
    "                if pred_type == \"Predictions\":\n",
    "                    thresholds = None\n",
    "                else:\n",
    "                    if thresholds:\n",
    "                        print(f\"on thresholds:\\n{thresholds}\")\n",
    "                    else:\n",
    "                        print(\"No thresholds\")\n",
    "                \n",
    "                self.classification_metrics(X,\n",
    "                                            y,\n",
    "                                            pred_name=pred_name,\n",
    "                                            dataset_name=dataset_name,\n",
    "                                            thresholds=thresholds,\n",
    "                                            ignore_metrics=ignore_metrics,\n",
    "                                            custom_metrics=custom_metrics,\n",
    "                                            average_scoring=average_scoring)\n",
    "\n",
    "                self.plot_confusion_matrix(X,\n",
    "                                           y,\n",
    "                                           pred_name=pred_name,\n",
    "                                           dataset_name=dataset_name,\n",
    "                                           thresholds=thresholds,\n",
    "                                           figsize=figsize,\n",
    "                                           normalize=normalize_confusion_matrix)\n",
    "\n",
    "                if pred_type == \"Probabilities\":\n",
    "                    self.plot_precision_recall_curve(X,\n",
    "                                                     y,\n",
    "                                                     pred_name=pred_name,\n",
    "                                                     dataset_name=dataset_name,\n",
    "                                                     figsize=figsize,\n",
    "                                                     thresholds=thresholds)\n",
    "                    self.plot_roc_curve(X,\n",
    "                                        y,\n",
    "                                        pred_name=pred_name,\n",
    "                                        dataset_name=dataset_name,\n",
    "                                        figsize=figsize,\n",
    "                                        thresholds=thresholds)\n",
    "\n",
    "                    if self.__binary_classifcation:\n",
    "                        self.plot_lift_curve(X,\n",
    "                                             y,\n",
    "                                             pred_name=pred_name,\n",
    "                                             dataset_name=dataset_name,\n",
    "                                             figsize=figsize,\n",
    "                                             thresholds=thresholds)\n",
    "                        self.plot_ks_statistic(X,\n",
    "                                               y,\n",
    "                                               pred_name=pred_name,\n",
    "                                               dataset_name=dataset_name,\n",
    "                                               figsize=figsize,\n",
    "                                               thresholds=thresholds)\n",
    "                        self.plot_calibration_curve(X,\n",
    "                                                    y,\n",
    "                                                    pred_name=pred_name,\n",
    "                                                    dataset_name=dataset_name,\n",
    "                                                    figsize=figsize,\n",
    "                                                    thresholds=thresholds)\n",
    "                        self.plot_cumulative_gain(X,\n",
    "                                                  y,\n",
    "                                                  pred_name=pred_name,\n",
    "                                                  dataset_name=dataset_name,\n",
    "                                                  figsize=figsize,\n",
    "                                                  thresholds=thresholds)\n",
    "                        \n",
    "                if self.__df_features:\n",
    "                    self.classification_error_analysis(X,\n",
    "                                                       y,\n",
    "                                                       pred_name=pred_name,\n",
    "                                                       dataset_name=dataset_name,\n",
    "                                                       thresholds=thresholds,\n",
    "                                                       display_analysis_graphs=display_analysis_graphs)\n",
    "\n",
    "                    if pred_type == \"Predictions\":\n",
    "                        break\n",
    "\n",
    "    def plot_calibration_curve(self,\n",
    "                               X,\n",
    "                               y,\n",
    "                               pred_name,\n",
    "                               dataset_name,\n",
    "                               thresholds=None,\n",
    "                               save_file=True,\n",
    "                               title=None,\n",
    "                               ax=None,\n",
    "                               cmap='nipy_spectral',\n",
    "                               figsize=None,\n",
    "                               title_fontsize='large',\n",
    "                               text_fontsize='medium'):\n",
    "\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned\n",
    "            stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "        \n",
    "        save_file:\n",
    "            Boolean value to wether or not to save the file. \n",
    "\n",
    "        From scikit-plot documentation (Note not all attributes are provided to you):\n",
    "        Link: http://tinyurl.com/y3ym5pyc\n",
    "        Returns/Descr:\n",
    "            Plots calibration curves for a set of classifier probability estimates.\n",
    "        \"\"\"\n",
    "        \n",
    "        filename = f'KS Statistic on {dataset_name}'\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "        if not title:\n",
    "            title = filename\n",
    "\n",
    "        skplt.metrics.plot_calibration_curve(y,\n",
    "                                             self.__get_model_probas(pred_name,\n",
    "                                                                     X),\n",
    "                                             title=title,\n",
    "                                             ax=ax,\n",
    "                                             cmap=cmap,\n",
    "                                             figsize=figsize,\n",
    "                                             title_fontsize=title_fontsize,\n",
    "                                             text_fontsize=text_fontsize)\n",
    "\n",
    "        if save_file:\n",
    "            create_plt_png(self.get_output_folder(),\n",
    "                           sub_dir,\n",
    "                           convert_to_filename(filename))\n",
    "\n",
    "        if self.__notebook_mode:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_roc_curve(self,\n",
    "                       X,\n",
    "                       y,\n",
    "                       pred_name,\n",
    "                       dataset_name,\n",
    "                       thresholds=None,\n",
    "                       save_file=True,\n",
    "                       title=None,\n",
    "                       ax=None,\n",
    "                       figsize=(10, 8),\n",
    "                       title_fontsize='large',\n",
    "                       text_fontsize='medium'):\n",
    "\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned\n",
    "            stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "        \n",
    "        save_file:\n",
    "            Boolean value to wether or not to save the file. \n",
    "\n",
    "        From scikit-plot documentation (Note not all attributes are provided to you):\n",
    "        Link: http://tinyurl.com/y3ym5pyc\n",
    "        Returns/Descr:\n",
    "            Creates ROC curves from labels and predicted probabilities.\n",
    "        \"\"\"\n",
    "        filename = f'Roc Curve on {dataset_name}'\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "        if not title:\n",
    "            title = filename\n",
    "\n",
    "        skplt.metrics.plot_roc(y,\n",
    "                               self.__get_model_probas(pred_name,\n",
    "                                                       X),\n",
    "                               title=title,\n",
    "                               ax=ax,\n",
    "                               figsize=figsize,\n",
    "                               title_fontsize=title_fontsize,\n",
    "                               text_fontsize=text_fontsize)\n",
    "\n",
    "        if save_file:\n",
    "            create_plt_png(self.get_output_folder(),\n",
    "                           sub_dir,\n",
    "                           convert_to_filename(filename))\n",
    "\n",
    "        if self.__notebook_mode:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_cumulative_gain(self,\n",
    "                             X,\n",
    "                             y,\n",
    "                             pred_name,\n",
    "                             dataset_name,\n",
    "                             thresholds=None,\n",
    "                             save_file=True,\n",
    "                             title=None,\n",
    "                             ax=None,\n",
    "                             figsize=(10, 8),\n",
    "                             title_fontsize='large',\n",
    "                             text_fontsize='medium'):\n",
    "\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned\n",
    "            stored in 'self.__pred_funcs_dict'.\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        save_file:\n",
    "            Boolean value to wether or not to save the file. \n",
    "\n",
    "        From scikit-plot documentation (Note not all attributes are provided to you):\n",
    "        Link: http://tinyurl.com/y3ym5pyc\n",
    "        Returns/Descr:\n",
    "        \"\"\"\n",
    "        filename = f'Cumulative Gain gain on {dataset_name}'\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "        if not title:\n",
    "            title = filename\n",
    "\n",
    "        skplt.metrics.plot_cumulative_gain(y,\n",
    "                                           self.__get_model_probas(pred_name,\n",
    "                                                                   X),\n",
    "                                           title=title,\n",
    "                                           ax=ax,\n",
    "                                           figsize=figsize,\n",
    "                                           title_fontsize=title_fontsize,\n",
    "                                           text_fontsize=text_fontsize)\n",
    "\n",
    "        if save_file:\n",
    "            create_plt_png(self.get_output_folder(),\n",
    "                           sub_dir,\n",
    "                           convert_to_filename(filename))\n",
    "\n",
    "        if self.__notebook_mode:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_precision_recall_curve(self,\n",
    "                                    X,\n",
    "                                    y,\n",
    "                                    pred_name,\n",
    "                                    dataset_name,\n",
    "                                    thresholds=None,\n",
    "                                    save_file=True,\n",
    "                                    title=None,\n",
    "                                    plot_micro=True,\n",
    "                                    classes_to_plot=None,\n",
    "                                    ax=None,\n",
    "                                    figsize=(10, 8),\n",
    "                                    cmap='nipy_spectral',\n",
    "                                    title_fontsize='large',\n",
    "                                    text_fontsize='medium'):\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned\n",
    "            stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        From scikit-plot documentation (Note not all attributes are provided to you):\n",
    "        Link: http://tinyurl.com/y3ym5pyc\n",
    "        Returns/Descr:\n",
    "            Creates a plot precision recall curve plot based on the models predictions.\n",
    "        \"\"\"\n",
    "\n",
    "        filename = f'Precision Recall on {dataset_name}'\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "        if not title:\n",
    "            title = filename\n",
    "\n",
    "        skplt.metrics.plot_precision_recall(y,\n",
    "                                            self.__get_model_probas(pred_name,\n",
    "                                                                    X),\n",
    "                                            title=title,\n",
    "                                            plot_micro=plot_micro,\n",
    "                                            classes_to_plot=classes_to_plot,\n",
    "                                            ax=ax,\n",
    "                                            figsize=figsize,\n",
    "                                            cmap=cmap,\n",
    "                                            title_fontsize=title_fontsize,\n",
    "                                            text_fontsize=text_fontsize)\n",
    "\n",
    "        if save_file:\n",
    "            create_plt_png(self.get_output_folder(),\n",
    "                           sub_dir,\n",
    "                           convert_to_filename(filename))\n",
    "\n",
    "        if self.__notebook_mode:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_lift_curve(self,\n",
    "                        X,\n",
    "                        y,\n",
    "                        pred_name,\n",
    "                        dataset_name,\n",
    "                        thresholds=None,\n",
    "                        save_file=True,\n",
    "                        title=None,\n",
    "                        ax=None,\n",
    "                        figsize=(10, 8),\n",
    "                        title_fontsize='large',\n",
    "                        text_fontsize='medium'):\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned\n",
    "            stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        From scikit-plot documentation (Note not all attributes are provided to you):\n",
    "        Link: http://tinyurl.com/y3ym5pyc\n",
    "        Returns/Descr:\n",
    "            Creates a plot precision recall curve plot based on the models predictions.\n",
    "        \"\"\"\n",
    "\n",
    "        filename = f'Lift Curve on {dataset_name}'\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "        if not title:\n",
    "            title = filename\n",
    "\n",
    "        skplt.metrics.plot_lift_curve(y,\n",
    "                                      self.__get_model_probas(pred_name,\n",
    "                                                              X),\n",
    "                                      thresholds=thresholds,\n",
    "                                      title=title,\n",
    "                                      ax=ax,\n",
    "                                      figsize=figsize,\n",
    "                                      title_fontsize=title_fontsize,\n",
    "                                      text_fontsize=text_fontsize)\n",
    "        if save_file:\n",
    "            create_plt_png(self.get_output_folder(),\n",
    "                           sub_dir,\n",
    "                           convert_to_filename(filename))\n",
    "\n",
    "        if self.__notebook_mode:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_confusion_matrix(self,\n",
    "                              X,\n",
    "                              y,\n",
    "                              pred_name,\n",
    "                              dataset_name,\n",
    "                              thresholds=None,\n",
    "                              save_file=True,\n",
    "                              title=None,\n",
    "                              normalize=False,\n",
    "                              hide_zeros=False,\n",
    "                              hide_counts=False,\n",
    "                              x_tick_rotation=0,\n",
    "                              ax=None,\n",
    "                              figsize=(10, 8),\n",
    "                              cmap='Blues',\n",
    "                              title_fontsize='large',\n",
    "                              text_fontsize='medium'):\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned\n",
    "            stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        From scikit-plot documentation (Note not all attributes are provided to you):\n",
    "        Link: http://tinyurl.com/y3ym5pyc\n",
    "        Returns/Descr:\n",
    "            Creates a confusion matrix plot based on the models predictions.\n",
    "        \"\"\"\n",
    "        filename = f'Confusion Matrix: {dataset_name}'\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "        if not title:\n",
    "            title = filename\n",
    "\n",
    "        warnings.filterwarnings('ignore')\n",
    "        skplt.metrics.plot_confusion_matrix(\n",
    "            self.__get_model_prediction(pred_name,\n",
    "                                        X,\n",
    "                                        thresholds),\n",
    "            y,\n",
    "            title=title,\n",
    "            normalize=normalize,\n",
    "            hide_zeros=hide_zeros,\n",
    "            hide_counts=hide_counts,\n",
    "            x_tick_rotation=x_tick_rotation,\n",
    "            ax=ax,\n",
    "            figsize=figsize,\n",
    "            cmap=cmap,\n",
    "            title_fontsize=title_fontsize,\n",
    "            text_fontsize=text_fontsize)\n",
    "        warnings.filterwarnings('default')\n",
    "\n",
    "        if save_file:\n",
    "            create_plt_png(self.get_output_folder(),\n",
    "                           sub_dir,\n",
    "                           convert_to_filename(filename))\n",
    "\n",
    "        if self.__notebook_mode:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def classification_metrics(self,\n",
    "                               X,\n",
    "                               y,\n",
    "                               pred_name,\n",
    "                               dataset_name,\n",
    "                               thresholds=None,\n",
    "                               save_file=True,\n",
    "                               title=\"\",\n",
    "                               custom_metrics=dict(),\n",
    "                               ignore_metrics=[],\n",
    "                               average_scoring=[\"micro\",\n",
    "                                                \"macro\",\n",
    "                                                \"weighted\"]):\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned stored\n",
    "            in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        save_file:\n",
    "            Determines whether or not to save the generated document.\n",
    "\n",
    "        title:\n",
    "            Adds to the column 'Metric Score'.\n",
    "\n",
    "        sub_dir:\n",
    "            Specify a subdirectory to append to the output path of the file.\n",
    "\n",
    "        custom_metrics:\n",
    "            Pass the name of metric(s) and the function definition(s) in a\n",
    "            dictionary.\n",
    "\n",
    "        ignore_metrics:\n",
    "            Specify the default metrics to not apply to the classification\n",
    "            analysis.\n",
    "                * Precision\n",
    "                * MCC\n",
    "                * Recall\n",
    "                * F1-Score\n",
    "                * Accuracy\n",
    "\n",
    "        average_scoring:\n",
    "            Determines the type of averaging performed on the data.\n",
    "                * micro\n",
    "                * macro\n",
    "                * weighted\n",
    "\n",
    "        Returns/Desc:\n",
    "            Creates/displays a dataframe object based on the model's\n",
    "            predictions on the feature matrix compared to target data.\n",
    "        \"\"\"\n",
    "        filename = f'Metric Evaluation on {dataset_name}'\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "\n",
    "        if not isinstance(average_scoring, list):\n",
    "            average_scoring = [average_scoring]\n",
    "\n",
    "        # Default metric name's and their function\n",
    "        metric_functions = dict()\n",
    "        metric_functions[\"Precision\"] = precision_score\n",
    "        metric_functions[\"MCC\"] = matthews_corrcoef\n",
    "        metric_functions[\"Recall\"] = recall_score\n",
    "        metric_functions[\"F1-Score\"] = f1_score\n",
    "        metric_functions[\"Accuracy\"] = accuracy_score\n",
    "\n",
    "        warnings.filterwarnings('ignore')\n",
    "\n",
    "        # Ignore default metrics if needed\n",
    "        for remove_metric in ignore_metrics:\n",
    "            if remove_metric in metric_functions:\n",
    "                del metric_functions[remove_metric]\n",
    "\n",
    "        # Add in custom metrics\n",
    "        if len(custom_metrics.keys()):\n",
    "            metric_functions.update(custom_metrics)\n",
    "\n",
    "        # Evaluate model on metrics\n",
    "        evaluation_report = dict()\n",
    "        for metric_name in metric_functions:\n",
    "            for average_score in average_scoring:\n",
    "\n",
    "                model_predictions = self.__get_model_prediction(pred_name,\n",
    "                                                                X,\n",
    "                                                                thresholds)\n",
    "                try:\n",
    "                    evaluation_report[f'{metric_name}({average_score})'] = \\\n",
    "                        metric_functions[metric_name](y_true=y,\n",
    "                                                      y_pred=model_predictions,\n",
    "                                                      average=average_score)\n",
    "                except TypeError:\n",
    "                    evaluation_report[metric_name] = metric_functions[\n",
    "                        metric_name](y,\n",
    "                                     model_predictions)\n",
    "                    break\n",
    "\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        warnings.filterwarnings('default')\n",
    "\n",
    "        if title and len(title) > 0:\n",
    "            index_name = f\"Metric Scores ({title})\"\n",
    "        else:\n",
    "            index_name = \"Metric Scores\"\n",
    "\n",
    "        # ---\n",
    "        evaluation_report = pd.DataFrame({index_name:\n",
    "                                              [f'{metric_score:.4f}'\n",
    "                                               for metric_score\n",
    "                                               in evaluation_report.values()]},\n",
    "                                         index=list(evaluation_report.keys()))\n",
    "\n",
    "        if self.__notebook_mode:\n",
    "            display(evaluation_report)\n",
    "        else:\n",
    "            print(evaluation_report)\n",
    "\n",
    "        if save_file:\n",
    "            # Create image file\n",
    "            df_to_image(evaluation_report,\n",
    "                        self.get_output_folder(),\n",
    "                        sub_dir,\n",
    "                        convert_to_filename(filename),\n",
    "                        col_width=20,\n",
    "                        show_index=True,\n",
    "                        format_float_pos=4)\n",
    "\n",
    "    def classification_error_analysis(self,\n",
    "                                      X,\n",
    "                                      y,\n",
    "                                      pred_name,\n",
    "                                      dataset_name,\n",
    "                                      thresholds=None,\n",
    "                                      save_file=True,\n",
    "                                      display_analysis_graphs=False):\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned\n",
    "            stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        save_file:\n",
    "            Determines whether or not to save the generated document.\n",
    "            \n",
    "        display_analysis_graphs:\n",
    "            Controls visual display of graph generation.\n",
    "\n",
    "        Returns/Descr:\n",
    "            Creates a directory structure of subsetted data produced by all correctly/predicted.\n",
    "        \"\"\"\n",
    "\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "\n",
    "        model_predictions = self.__get_model_prediction(pred_name,\n",
    "                                                        X,\n",
    "                                                        thresholds=thresholds)\n",
    "\n",
    "        if sum(model_predictions == y):\n",
    "            if display_analysis_graphs:\n",
    "                print(\"\\n\\n\" + \"*\" * 10 +\n",
    "                      \"Correctly predicted analysis\"\n",
    "                      + \"*\" * 10 + \"\\n\")\n",
    "            else:\n",
    "                print(\"\\n\\n\" + \"*\" * 10 +\n",
    "                      \"Generating graphs for model's correctly predicted...\" +\n",
    "                      \"*\" * 10 + \"\\n\")\n",
    "                DataAnalysis(pd.DataFrame(X[model_predictions == y],\n",
    "                                          columns=self.__df_features.get_all_features()),\n",
    "                             self.__df_features,\n",
    "                             overwrite_full_path=self.get_output_folder() +\n",
    "                                                 sub_dir + \"/Correctly Predicted Data/\",\n",
    "                             missing_data_visuals=False,\n",
    "                             notebook_mode=display_analysis_graphs)\n",
    "        else:\n",
    "            print(\"Your model predicted nothing correctly...dam that sucks\")\n",
    "\n",
    "        if sum(model_predictions != y):\n",
    "            if display_analysis_graphs:\n",
    "                print(\"\\n\\n\" + \"*\" * 10 +\n",
    "                      \"Incorrectly predicted analysis\"\n",
    "                      + \"*\" * 10 + \"\\n\")\n",
    "            else:\n",
    "                print(\"\\n\\n\" + \"*\" * 10 +\n",
    "                      \"Generating graphs for model's incorrectly predicted...\" +\n",
    "                      \"*\" * 10 + \"\\n\")\n",
    "            \n",
    "#             for target_value in self.__target_values:\n",
    "                \n",
    "\n",
    "            DataAnalysis(pd.DataFrame(X[model_predictions != y],\n",
    "                                      columns=self.__df_features.get_all_features()),\n",
    "                         self.__df_features,\n",
    "                         overwrite_full_path=self.get_output_folder() +\n",
    "                                             sub_dir + \"/Incorrectly Predicted Data/\",\n",
    "                         missing_data_visuals=False,\n",
    "                         notebook_mode=display_analysis_graphs)\n",
    "        else:\n",
    "            print(\n",
    "                \"\\n\\nYour model predicted everything correctly...there is something very wrong here...\")\n",
    "\n",
    "    def classification_report(self,\n",
    "                              X,\n",
    "                              y,\n",
    "                              pred_name,\n",
    "                              dataset_name,\n",
    "                              thresholds=None,\n",
    "                              save_file=True):\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned\n",
    "            stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        save_file:\n",
    "            Determines whether or not to save the generated document.\n",
    "\n",
    "        Returns/Descr:\n",
    "            Creates a report of all target's metric evaluations\n",
    "            based on the model's prediction output.\n",
    "        \"\"\"\n",
    "        filename = f'Classification Report {dataset_name}'\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "\n",
    "        # Create dataframe report\n",
    "        report_df = pd.DataFrame(classification_report(y,\n",
    "                                                       self.__get_model_prediction(\n",
    "                                                           pred_name,\n",
    "                                                           X,\n",
    "                                                           thresholds),\n",
    "                                                       output_dict=True))\n",
    "\n",
    "        # ---\n",
    "        if self.__notebook_mode:\n",
    "            display(report_df)\n",
    "        else:\n",
    "            print(report_df)\n",
    "\n",
    "        if save_file:\n",
    "            # Output dataframe as png\n",
    "            df_to_image(report_df,\n",
    "                        self.get_output_folder(),\n",
    "                        sub_dir,\n",
    "                        filename,\n",
    "                        col_width=20,\n",
    "                        show_index=True,\n",
    "                        format_float_pos=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_analysis = ClassificationAnalysis(model=model,\n",
    "                                     pred_funcs_dict={\"Probabilities function\":model.predict_proba,\n",
    "                                                      \"Predict function\":model.predict},\n",
    "                                     sample_data=X_train,\n",
    "                                     model_name=repr(model).split(\"(\")[0],\n",
    "                                     project_name=f'{parent_project_name}/Classification Analysis',\n",
    "                                     notebook_mode=True,\n",
    "                                     df_features=df_features)\n",
    "\n",
    "dt_analysis.perform_analysis(X=X_train,\n",
    "                             y=y_train,\n",
    "                             dataset_name=\"Training Data\",\n",
    "                             thresholds_matrix=[[.2,.2,.2,.2,.2,.2,.2,.2,.2,.2,.2],\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(\"/Users/ericcacciavillani/Desktop/Coding/Python_Files/Artificial_Intelligence/Data Mining/eFlowMaster/Testing/eFlow Data/Pre processing/Supervised Analysis/DecisionTreeClassifier/Probabilities function/Thresholds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_unique_directory_path(os.getcwd() + \"/eFlow Data/Pre processing/Supervised Analysis/DecisionTreeClassifier/Test data/Probability Classification/\",\n",
    "                        \"Model Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_string = os.getcwd().replace(\"/\", \"///\")\n",
    "error_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = \"/Users/ericcacciavillani/Desktop/Coding/Python_Files/Artificial_Intelligence/Data Mining/eFlowMaster/Testing/eFlow Data/Pre processing/Supervised Analysis/DecisionTreeClassifier/Test data/Probability Classification\"\n",
    "correct_directory_path(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[[1,2],[1,2,3],[1]]\n",
    "c = copy.deepcopy(a)\n",
    "b=np.array(a)\n",
    "b.tolist()\n",
    "hhh = None\n",
    "if hhh:\n",
    "    print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb = None\n",
    "\n",
    "if not bbb:\n",
    "    print(\"test\")\n",
    "else:\n",
    "    print(\"fff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_y = copy.deepcopy(y_test)\n",
    "vector_y = np.where(vector_y==0, \"Test\", vector_y) \n",
    "vector_y = np.where(vector_y=='1', \"Blarg\", vector_y)\n",
    "vector_y = np.where(vector_y=='2', \"Dragon\", vector_y)\n",
    "vector_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(vector_y, vector_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0, 0, 8.3, 0, 0, 0, 0, 0, 0, 0, .36]\n",
    "\n",
    "model_output = model.predict_proba(X_train)\n",
    "\n",
    "print(model_output)\n",
    "# Validate probabilities\n",
    "if thresholds:\n",
    "    if isinstance(thresholds, list) or \\\n",
    "            isinstance(thresholds, np.ndarray):\n",
    "        if sum(thresholds) < .98:\n",
    "            print(\"Thresholds didn't add up to 98%-100%! \"\n",
    "                  \"This may cause issues in your results!\")\n",
    "    else:\n",
    "        raise ThresholdType\n",
    "\n",
    "# ---\n",
    "if isinstance(model_output, list):\n",
    "    model_output = np.asarray(model_output)\n",
    "\n",
    "if isinstance(model_output, np.ndarray):\n",
    "    if thresholds:\n",
    "        outputs_passed_threshold = model_output > np.asarray(thresholds)\n",
    "outputs_passed_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "class UnExpectedData(UserWarning, ValueError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = model.predict_proba(X_train)\n",
    "bool_matrix_thresholds = model_output < np.asarray([.2,.2,.2,.2,.2,.2,.2,.2,.2,.2,.2])\n",
    "\n",
    "tmp_matrix = []\n",
    "for bool_vector in bool_matrix_thresholds:\n",
    "    tmp_vector = []\n",
    "    for i,passed in enumerate(bool_vector):\n",
    "        if passed:\n",
    "            tmp_vector.append(model_output[i][0])\n",
    "        else:\n",
    "            tmp_vector.append(float(\"-inf\"))\n",
    "    tmp_matrix.append(tmp_vector)\n",
    "print(tmp_matrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = msno.bar(df[df.columns[df.isna().any()].tolist()],\n",
    "              color=\"#072F5F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.isnull().sum().index.tolist()\n",
    "null_values = df.isnull().sum().values.tolist()\n",
    "null_sorted_features, null_values = zip(*sorted(zip(null_values,\n",
    "                                                    features)))\n",
    "\n",
    "for feature_index, value in enumerate(null_values):\n",
    "    if value == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eflow._hidden.utils.meta_data_identity import check_create_metadata_of_dataframe\n",
    "testing_path = \"/Users/ericcacciavillani/Desktop/Coding/Python_Files/Artificial_Intelligence/Data Mining/eFlowMaster/Testing/eflow Data/Pre processing/Missing Data/All Data\"\n",
    "check_create_metadata_of_dataframe(df,\n",
    "                                   testing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "feature_name = \"Feature_name\"\n",
    "for hash_type in [1,2,3,4,5,6,7,8,9,10]:\n",
    "    result = 0\n",
    "    for char_index, char in enumerate(feature_name):\n",
    "        if hash_type == 1:\n",
    "            result += int(ord(char))\n",
    "        elif hash_type == 2:\n",
    "            result += int(ord(char) + 62 * ord(char))\n",
    "        elif hash_type == 3:\n",
    "            result += int(ord(char) + 147 * ord(char))\n",
    "        elif hash_type == 4:\n",
    "            result += int((ord(char) + 92) * math.pow(ord(char), 3))\n",
    "        elif hash_type == 5:\n",
    "            result += int(ord(char) + 49 * math.pow(ord(char), 2))\n",
    "        elif hash_type == 6:\n",
    "            result += int((23 + ord(char) + 45) * (3 + ord(char) + 2))\n",
    "        elif hash_type == 7:\n",
    "            result += int((ord(char) * 5) + 32 + 8)\n",
    "        elif hash_type == 8:\n",
    "            result += int(math.pow(ord(char), 2))\n",
    "        elif hash_type == 9:\n",
    "            result += int(ord(char) * 2 + 32 + ord(char) * 2 + 5)\n",
    "        elif hash_type == 10:\n",
    "            result += int(ord(char) * 12 + 76 + math.pow(ord(char), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Ticket\"][891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1,2,3]) % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Age\" in {'Aged', 'Fare'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
