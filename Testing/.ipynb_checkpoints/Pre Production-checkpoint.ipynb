{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import ipython_blocking\n",
    "from pivottablejs import pivot_ui\n",
    "import scikitplot as skplt\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from eflow import DataFrameTypes\n",
    "from eflow.analysis import DataAnalysis\n",
    "from eflow.pipeline_segments import DataCleaner\n",
    "from eflow.analysis import MissingDataAnalysis\n",
    "from eflow.utils.pandas_utils import data_types_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [1, 5], 2: [1, 2], 3: [1, 2, 5], 4: [1, 2], 6: [5], 7: [5]}\n"
     ]
    }
   ],
   "source": [
    "def revdict(d):\n",
    "    r = {}\n",
    "    for k in d:\n",
    "        for v in d[k]:\n",
    "            if v not in r:\n",
    "                r[v] = [k]\n",
    "            else:\n",
    "                r[v].append(k)\n",
    "    return r\n",
    "d={1:[1,2,3,4],2:[2,3,4],5:[1,3,6,7]}\n",
    "a = revdict(d)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be sure to run the following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Worflow Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (This should be the only place you should have to declare anything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"Datasets/titanic_train.csv\"\n",
    "target_column = \"Survived\"\n",
    "parent_project_name = \"Pre processing\"\n",
    "prediction_method = \"Classification\"\n",
    "notebook_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(dataset_path)\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Types</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Features</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Data Types\n",
       "Features              \n",
       "Age            float64\n",
       "Fare           float64\n",
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Ticket          object\n",
       "Cabin           object\n",
       "Embarked        object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_types_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction tool for dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"Piviot_Table_JS.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a1b672780>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_ui(df,\n",
    "         outfile_path='Piviot_Table_JS.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating graph for null dendrogram graph...\n"
     ]
    },
    {
     "ename": "MismatchError",
     "evalue": "DataFrameSnapshot has raised an error because :\n\tFeature 'Age' is supposed to be in 'float_features' was found to be in 'bool_features'\n\tFeature 'Sex' is supposed to be in 'categorical_features' was found to be in 'bool_features'.\nThis error invoked because the directory structure saved a json file containing attributes of the dataframe or a 'snapshot'.\nThe given error can be resolved by performing any of the following:\n\t* Pass in the same dataframe as expected.\n\t* Disable the identity check by changing 'identity_check' to False.\n\t* Disable save file option by changing the parameter 'save_file' to False.\n\t* Or deleting the json object file in the dataset directory under _Extras",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMismatchError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-95a9ac9fa15c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtester\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sex\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtester\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sex\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Blarg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m missing_data_analysis.plot_null_dendrogram_graph(tester,\n\u001b[0;32m----> 9\u001b[0;31m                                                  \"All Data\")\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Coding/Python_Files/Artificial_Intelligence/Data Mining/eFlow/eflow/analysis/missing_data_analysis.py\u001b[0m in \u001b[0;36mplot_null_dendrogram_graph\u001b[0;34m(self, df, dataset_name, null_features_only, display_visuals, filename, save_file, dataframe_snapshot, method, filter, n, p, orientation, figsize, fontsize, inline, ax)\u001b[0m\n\u001b[1;32m    612\u001b[0m                     df_snapshot.check_create_snapshot(df,\n\u001b[1;32m    613\u001b[0m                                                       \u001b[0mdirectory_pth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m                                                       sub_dir=f\"{dataset_name}/_Extras\")\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             create_plt_png(self.get_output_folder(),\n",
      "\u001b[0;32m~/Desktop/Coding/Python_Files/Artificial_Intelligence/Data Mining/eFlow/eflow/_hidden/objects/dataframe_snapshot.py\u001b[0m in \u001b[0;36mcheck_create_snapshot\u001b[0;34m(self, df, directory_pth, sub_dir)\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmismatch_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                     raise MismatchError(f\"DataFrameSnapshot has raised an error because {mismatch_error}.\" +\n\u001b[0;32m--> 359\u001b[0;31m                                         \u001b[0;34m\"\\nThis error invoked because the directory structure saved a json file \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                                         \u001b[0;34m\"containing attributes of the dataframe or a 'snapshot'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                                         \u001b[0;34m\"\\nThe given error can be resolved by performing any of the following:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMismatchError\u001b[0m: DataFrameSnapshot has raised an error because :\n\tFeature 'Age' is supposed to be in 'float_features' was found to be in 'bool_features'\n\tFeature 'Sex' is supposed to be in 'categorical_features' was found to be in 'bool_features'.\nThis error invoked because the directory structure saved a json file containing attributes of the dataframe or a 'snapshot'.\nThe given error can be resolved by performing any of the following:\n\t* Pass in the same dataframe as expected.\n\t* Disable the identity check by changing 'identity_check' to False.\n\t* Disable save file option by changing the parameter 'save_file' to False.\n\t* Or deleting the json object file in the dataset directory under _Extras"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "missing_data_analysis = MissingDataAnalysis(sub_dir=parent_project_name)\n",
    "# missing_data_analysis.perform_analysis(df.head(42),\n",
    "#                                        \"All Data\")\n",
    "tester = copy.deepcopy(df)\n",
    "tester[\"Age\"] = tester[\"Age\"]\n",
    "missing_data_analysis.plot_null_dendrogram_graph(tester,\n",
    "                                                 \"All Data\")\n",
    "raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = widgets.SelectMultiple(\n",
    "#     options=['Apples', 'Oranges', 'Pears'],\n",
    "#     value=['Oranges'],\n",
    "#     #rows=10,\n",
    "#     description='Fruits',\n",
    "#     disabled=False\n",
    "# )\n",
    "# del w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = str(u\"\\u2192\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Un-Wanted Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do not remove nans yet, let the datacleaner do it's job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Name\",\n",
    "                 \"Ticket\",\n",
    "                 \"PassengerId\"],\n",
    "        inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "dt = parser.parse(\"Aug 28 1999 12:00AM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date_test\"] = [\"2019-01-02\" for _ in range(0,df.shape[0])]\n",
    "df[\"Date_test\"][0] = np.nan\n",
    "# df[\"Date_test\"] = [parser.parse(val)for val in df[\"Date_test\"].value_counts().keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Feature manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change cabin column to have the level on the ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cabin\"] = df[\"Cabin\"].str.replace(r'\\d+', '').str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Feature Data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make given data type changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Pclass\"] = df[\"Pclass\"].replace(1, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final look at data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up DataFrameTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = DataFrameTypes(df,\n",
    "                             target_column=target_column,\n",
    "                             ignore_nulls=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skim through Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col not in df_features.get_float_features() and len(np.unique(df[col].dropna().values)) <= 12:\n",
    "        display(df[col].value_counts())\n",
    "        print(\"***\" * 4 + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform quick analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_obj = DataAnalysis(df,\n",
    "                            df_features,\n",
    "                            project_name=f'{parent_project_name}/General Analysis (Before Cleaning)',\n",
    "                            missing_data_visuals=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner = DataCleaner(df,\n",
    "                           project_name=f'{parent_project_name}/Data Cleaning',\n",
    "                           missing_data_visuals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner.data_cleaning_widget(df,\n",
    "                                  df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner.get_last_saved_json_file_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner.data_cleaning_with_json_file(df,\n",
    "                                          data_cleaner.get_last_saved_json_file_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from impyute.imputation.cs import mice\n",
    "\n",
    "a = df[\"Age\"].tolist()\n",
    "# start the MICE training\n",
    "imputed_training=mice(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datawig\n",
    "\n",
    "df_train, df_test = datawig.utils.random_split(df)\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer = datawig.SimpleImputer(\n",
    "    input_columns=['Survived', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Fare', 'Cabin','Embarked'], # column(s) containing information about the column we want to impute\n",
    "    output_column= 'Age', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer.fit(train_df=df, num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_training=mice(df[df_features.get_numerical_features()].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datawig\n",
    "# !pip install opencv-python\n",
    "# !pip install Pillow\n",
    "# !pip install tesserocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "df[\"Cabin\"] = df[\"Cabin\"].fillna(\"A\")\n",
    "test = df.drop(columns=[\"Date_test\", \"Embarked\"]).dropna()\n",
    "\n",
    "test[\"Cabin\"] = df[\"Cabin\"] == \"B\"\n",
    "test[\"Sex\"] = df[\"Sex\"] == \"male\"\n",
    "test[target_column] = [random.randint(0, 10) for _ in range(0,test.shape[0])]\n",
    "print(len(test[target_column]))\n",
    "\n",
    "y = test[target_column].values\n",
    "X = test.values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "df_features = DataFrameTypes(test,\n",
    "                             target_column=target_column,\n",
    "                             ignore_nulls=True) \n",
    "df_features.get_all_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=517, stratify=y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from eflow.modeling import optimize_model_grid\n",
    "# Find best parameters for model\n",
    "param_grid = {\n",
    "    \"max_depth\": list(range(2, 3)),\n",
    "    \"min_samples_leaf\": list(range(80, 130, 5)),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "#     \"n_splits\": [20, 30]\n",
    "}\n",
    "\n",
    "model, best_params = optimize_model_grid(\n",
    "    model=DecisionTreeClassifier(),\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    param_grid=param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eflow._hidden.Objects.enum import enum\n",
    "from eflow.utils.sys_utils import create_plt_png, convert_to_filename, \\\n",
    "    df_to_image, write_object_text_to_file, get_unique_directory_path, \\\n",
    "    pickle_object_to_file\n",
    "from eflow._hidden.Objects.FileOutput import *\n",
    "from eflow._hidden.CustomExc import *\n",
    "from eflow.analysis import DataAnalysis\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "import scikitplot as skplt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import copy\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ClassificationAnalysis(FileOutput):\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 model_name,\n",
    "                 pred_funcs_dict,\n",
    "                 sample_data,\n",
    "                 project_name=\"Classification analysis_objects\",\n",
    "                 overwrite_full_path=None,\n",
    "                 notebook_mode=True,\n",
    "                 target_classes=None,\n",
    "                 df_features=None,\n",
    "                 columns=[],\n",
    "                 save_model=True):\n",
    "        \"\"\"\n",
    "        model:\n",
    "            A fitted supervised machine learning model.\n",
    "\n",
    "        model_name:\n",
    "            The name of the model in string form.\n",
    "\n",
    "        pred_funcs_dict:\n",
    "            A dict of the name of the function and the function defintion for the\n",
    "            model prediction methods.\n",
    "            (Can handle either a return of probabilities or a singile value.)\n",
    "            Init Example:\n",
    "            pred_funcs = dict()\n",
    "            pred_funcs[\"Predictions\"] = model.predict\n",
    "            pred_funcs[\"Probabilities\"] = model.probas\n",
    "         \n",
    "        sample_data:\n",
    "            Given data to then pass into our prediction functions to get a\n",
    "            resultant to get the classification prediction 'type'. \n",
    "\n",
    "        project_name:\n",
    "            Creates a parent or \"project\" folder in which all sub-directories\n",
    "            will be inner nested.\n",
    "\n",
    "        overwrite_full_path:\n",
    "            Overwrites the path to the parent folder.\n",
    "\n",
    "        notebook_mode:\n",
    "            If in a python notebook display in the notebook.\n",
    "\n",
    "        target_classes:\n",
    "            Specfied list/np.array of targeted classes the model predicts. If set to\n",
    "            none then it will attempt to pull from the sklearn's default attribute\n",
    "            '.classes_'.\n",
    "\n",
    "        df_features:\n",
    "            DataFrameTypeHolder object. If initalized we can run correct/error\n",
    "            analysis on the dataframe. Will save object in a pickle file and provided columns\n",
    "            if initalized and df_features is not initalized.\n",
    "\n",
    "        columns:\n",
    "            Will overwrite over df_features (DataFrameTypeHolder) regardless \n",
    "            of whether or not df_features is init.\n",
    "            \n",
    "        Returns/Desc:\n",
    "            Evaluates the given model based on the prediction functions pased to it.\n",
    "            Saves the model and other various graphs/dataframes for evaluation.\n",
    "        \"\"\"\n",
    "\n",
    "        # Init any parent objects\n",
    "        FileOutput.__init__(self,\n",
    "                            f'{project_name}/{model_name}',\n",
    "                            overwrite_full_path)\n",
    "\n",
    "        # Init objects without pass by refrence\n",
    "        self.__model = copy.deepcopy(model)\n",
    "        self.__model_name = copy.deepcopy(model_name)\n",
    "        self.__notebook_mode = copy.deepcopy(notebook_mode)\n",
    "        self.__target_values = copy.deepcopy(target_classes)\n",
    "        self.__df_features = copy.deepcopy(df_features)\n",
    "        self.__pred_funcs_dict = copy.deepcopy(pred_funcs_dict)\n",
    "        self.__pred_funcs_types = dict()\n",
    "\n",
    "        # Init on sklearns default target classes attribute\n",
    "        if not self.__target_values:\n",
    "            self.__target_values = copy.deepcopy(model.classes_)\n",
    "        # ---\n",
    "        if len(self.__target_values) != 2:\n",
    "            self.__binary_classifcation = False\n",
    "        else:\n",
    "            self.__binary_classifcation = True\n",
    "\n",
    "        # Save machine learning model\n",
    "        if save_model:\n",
    "            pickle_object_to_file(self.__model,\n",
    "                                  self.get_output_folder(),\n",
    "                                  f'{self.__model_name}')\n",
    "\n",
    "        # ---\n",
    "        check_create_dir_structure(self.get_output_folder(),\n",
    "                                   \"Extras\")\n",
    "        # Save predicted classes\n",
    "        write_object_text_to_file(self.__target_values,\n",
    "                                  self.get_output_folder() + \"Extras\",\n",
    "                                  \"_Classes\")\n",
    "\n",
    "        # Save features and or df_features object\n",
    "        if columns or df_features:\n",
    "            if columns:\n",
    "                write_object_text_to_file(columns,\n",
    "                                          self.get_output_folder() + \"Extras\",\n",
    "                                          \"_Features\")\n",
    "            else:\n",
    "                write_object_text_to_file(df_features.get_all_features(),\n",
    "                                          self.get_output_folder() + \"Extras\",\n",
    "                                          \"_Features\")\n",
    "                pickle_object_to_file(self.__model,\n",
    "                                      self.get_output_folder() + \"Extras\",\n",
    "                                      \"_df_features\")\n",
    "\n",
    "        # Find the 'type' of each prediction. Probabilities or Predictions\n",
    "        if self.__pred_funcs_dict:\n",
    "            for pred_name, pred_func in self.__pred_funcs_dict.items():\n",
    "                model_output = pred_func(\n",
    "                    np.reshape(sample_data[0],\n",
    "                               (-1, sample_data.shape[1])))[0]\n",
    "\n",
    "                # Confidence / Probability (Continuous output)\n",
    "                if isinstance(model_output, list) or isinstance(model_output,\n",
    "                                                                np.ndarray):\n",
    "                    self.__pred_funcs_types[pred_name] = \"Probabilities\"\n",
    "\n",
    "                    # Classification (Discrete output)\n",
    "                else:\n",
    "                    self.__pred_funcs_types[pred_name] = \"Predictions\"\n",
    "        else:\n",
    "            raise RequiresPredictionMethods\n",
    "\n",
    "    def __get_model_prediction(self,\n",
    "                               pred_name,\n",
    "                               X,\n",
    "                               thresholds=None):\n",
    "        \"\"\"\n",
    "        X:\n",
    "            Feature matrix.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        Returns/Desc:\n",
    "            Returns back a predicted value based for a given matrix.\n",
    "            Handles prediction function 'types' Predictions and Probabilities.\n",
    "            Helps streamline the entire process of evaluating classes.\n",
    "        \"\"\"\n",
    "        # DEBUG_MARKER\n",
    "\n",
    "        # Must be a prediction function\n",
    "        if self.__pred_funcs_types[pred_name] == \"Predictions\":\n",
    "            return self.__pred_funcs_dict[pred_name](X)\n",
    "\n",
    "        elif self.__pred_funcs_types[pred_name] == \"Probabilities\":\n",
    "            \n",
    "            # Validate probabilities\n",
    "            if thresholds:\n",
    "                if isinstance(thresholds, list) or \\\n",
    "                        isinstance(thresholds, np.ndarray):\n",
    "                    if len(thresholds) != len(self.__target_values):\n",
    "                        raise ThresholdLength\n",
    "                else:\n",
    "                    raise ThresholdType\n",
    "\n",
    "            model_output = self.__get_model_probas(pred_name,\n",
    "                                                   X)\n",
    "            if not thresholds:\n",
    "                return np.asarray([self.__target_values[np.argmax(proba)]\n",
    "                                   for proba in model_output])\n",
    "                \n",
    "            \n",
    "            bool_matrix_thresholds = model_output < thresholds\n",
    "            \n",
    "            prob_passed_matrix = np.asarray([\n",
    "                np.asarray([model_output[i][0] if passed else float(\"-inf\") \n",
    "                            for i,passed in enumerate(bool_vector)])\n",
    "                for bool_vector in bool_matrix_thresholds])            \n",
    "\n",
    "            model_predictions = np.asarray([self.__target_values[np.argmax(proba_vector)]\n",
    "                                            if sum(proba_vector != float(\"-inf\")) > 0 \n",
    "                                            else self.__target_values[np.argmax(model_output)]\n",
    "                                            for proba_vector in prob_passed_matrix])\n",
    "            return model_predictions\n",
    "        else:\n",
    "            raise UnknownModelOutputType\n",
    "\n",
    "    def __get_model_probas(self,\n",
    "                           pred_name,\n",
    "                           X):\n",
    "        \"\"\"\n",
    "        X:\n",
    "            Feature matrix.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        Returns/Desc:\n",
    "            Returns back a series of values between 0-1 to represent it's confidence.\n",
    "            Invokes an error if the prediction function call is anything but a Probabilities\n",
    "            call.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.__pred_funcs_types[pred_name] == \"Probabilities\":\n",
    "            model_output = self.__pred_funcs_dict[pred_name](X)\n",
    "\n",
    "            # ---\n",
    "            if isinstance(model_output, list):\n",
    "                model_output = np.asarray(model_output)\n",
    "\n",
    "            return model_output\n",
    "        else:\n",
    "            raise ProbasNotPossible\n",
    "\n",
    "    def __create_sub_dir_with_thresholds(self,\n",
    "                                         pred_name,\n",
    "                                         dataset_name,\n",
    "                                         thresholds):\n",
    "        \"\"\"\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The passed in dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        Returns/Desc:\n",
    "            Looking at the root of the starting directory and looking at each\n",
    "            '_Thresholds.txt' file to determine if the files can be outputed\n",
    "            to that directory. The content of the file must match the content\n",
    "            of the list/numpy array 'thresholds'.\n",
    "        \"\"\"\n",
    "        sub_dir = f'{dataset_name}/{pred_name}'\n",
    "\n",
    "        # Only generate extra folder structure if function type is Probabilities\n",
    "        if self.__pred_funcs_types[pred_name] == \"Probabilities\":\n",
    "\n",
    "            # ------\n",
    "            if not thresholds:\n",
    "                sub_dir = f'{sub_dir}/No Thresholds'\n",
    "            else:\n",
    "                i = 0\n",
    "                sub_dir = f'{sub_dir}/Thresholds'\n",
    "                tmp_sub_dir = copy.deepcopy(sub_dir)\n",
    "                while True:\n",
    "                    threshold_dir = self.get_output_folder()\n",
    "                    if i > 0:\n",
    "                        tmp_sub_dir = (sub_dir + f' {i}')\n",
    "                    threshold_dir += tmp_sub_dir\n",
    "\n",
    "                    # If file exists with the same thresholds; than use this directory\n",
    "                    if os.path.exists(threshold_dir):\n",
    "                        if self.__compare_thresholds_to_saved_thresholds(\n",
    "                                threshold_dir,\n",
    "                                thresholds):\n",
    "                            sub_dir = tmp_sub_dir\n",
    "                            break\n",
    "\n",
    "                    # Create new directory\n",
    "                    else:\n",
    "                        os.makedirs(threshold_dir)\n",
    "                        write_object_text_to_file(thresholds,\n",
    "                                                  threshold_dir,\n",
    "                                                  \"_Thresholds\")\n",
    "                        sub_dir = tmp_sub_dir\n",
    "                        break\n",
    "\n",
    "                    # Iterate for directory name change\n",
    "                    i += 1\n",
    "\n",
    "        return sub_dir\n",
    "\n",
    "    def __compare_thresholds_to_saved_thresholds(self,\n",
    "                                                 directory_pth,\n",
    "                                                 thresholds):\n",
    "        \"\"\"\n",
    "        directory_pth:\n",
    "            Path to the given folder where the \"_Thresholds.txt\"\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        Returns/Desc:\n",
    "            Compare the thresholds object to the text file; returns true if\n",
    "            the file exists and the object's value matches up.\n",
    "        \"\"\"\n",
    "\n",
    "        file_directory = correct_directory_path(directory_pth)\n",
    "\n",
    "        if os.path.exists(file_directory):\n",
    "\n",
    "            # Extract file contents and convert to a list object\n",
    "            file = open(file_directory + \"_Thresholds.txt\", \"r\")\n",
    "            line = file.read()\n",
    "            converted_list = line.split(\"=\")[-1].strip().strip('][').split(\n",
    "                ', ')\n",
    "            converted_list = [float(val) for val in converted_list]\n",
    "            file.close()\n",
    "\n",
    "            if thresholds == converted_list:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def peform_analysis(self,\n",
    "                        X,\n",
    "                        y,\n",
    "                        dataset_name,\n",
    "                        thresholds_matrix=None,\n",
    "                        figsize=(10, 8),\n",
    "                        normalize_confusion_matrix=True,\n",
    "                        ignore_metrics=[],\n",
    "                        custom_metrics=dict(),\n",
    "                        average_scoring=[\"micro\",\n",
    "                                         \"macro\",\n",
    "                                         \"weighted\"],\n",
    "                        display_analysis_graphs=False):\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds_matrix:\n",
    "            List of list/Matrix of thresholds\n",
    "\n",
    "            each thresholds:\n",
    "                If the model outputs a probability list/numpy array then we apply\n",
    "                thresholds to the ouput of the model.\n",
    "                For classification only; will not affect the direct output of\n",
    "                the probabilities.\n",
    "\n",
    "        figsize:\n",
    "            Plot's dimension's.\n",
    "\n",
    "        normalize_confusion_matrix:\n",
    "            Normalize the confusion matrix buckets.\n",
    "\n",
    "        ignore_metrics:\n",
    "            Specify set metrics to ignore. (F1-Score, Accuracy etc).\n",
    "\n",
    "        ignore_metrics:\n",
    "            Specify the default metrics to not apply to the classification\n",
    "            analysis.\n",
    "                * Precision\n",
    "                * MCC\n",
    "                * Recall\n",
    "                * F1-Score\n",
    "                * Accuracy\n",
    "\n",
    "        custom_metrics:\n",
    "            Pass the name of metric(s) and the function definition(s) in a\n",
    "            dictionary.\n",
    "\n",
    "        average_scoring:\n",
    "            Determines the type of averaging performed on the data.\n",
    "\n",
    "        display_analysis_graphs:\n",
    "            Controls visual display of error error analysis if it is able to run.\n",
    "\n",
    "        Returns/Desc:\n",
    "            Performs all classification functionality with the provided feature\n",
    "            data and target data.\n",
    "                * plot_precision_recall_curve\n",
    "                * classification_evaluation\n",
    "                * plot_confusion_matrix\n",
    "        \"\"\"\n",
    "        if isinstance(thresholds_matrix, np.ndarray):\n",
    "            thresholds_matrix = thresholds_matrix.tolist()\n",
    "\n",
    "        if not thresholds_matrix:\n",
    "            thresholds_matrix = list()\n",
    "\n",
    "        if isinstance(thresholds_matrix, list) and not isinstance(\n",
    "                thresholds_matrix[0], list):\n",
    "            thresholds_matrix = list(thresholds_matrix)\n",
    "        \n",
    "        \n",
    "        if None not in thresholds_matrix:\n",
    "            thresholds_matrix.append(None)\n",
    "\n",
    "        print(\"\\n\\n\" + \"---\" * 10 + f'{dataset_name}' + \"---\" * 10)\n",
    "\n",
    "        for pred_name, pred_type in self.__pred_funcs_types.items():\n",
    "            print(f\"Now running classification on {pred_name}\", end = '')\n",
    "            print(\"hit\")\n",
    "            for thresholds in thresholds_matrix:\n",
    "                if pred_type == \"Predictions\":\n",
    "                    thresholds = None\n",
    "                else:\n",
    "                    if thresholds:\n",
    "                        print(f\"on thresholds:\\n{thresholds}\")\n",
    "                    else:\n",
    "                        print(\"No thresholds\")\n",
    "                \n",
    "                self.classification_metrics(X,\n",
    "                                            y,\n",
    "                                            pred_name=pred_name,\n",
    "                                            dataset_name=dataset_name,\n",
    "                                            thresholds=thresholds,\n",
    "                                            ignore_metrics=ignore_metrics,\n",
    "                                            custom_metrics=custom_metrics,\n",
    "                                            average_scoring=average_scoring)\n",
    "\n",
    "                self.plot_confusion_matrix(X,\n",
    "                                           y,\n",
    "                                           pred_name=pred_name,\n",
    "                                           dataset_name=dataset_name,\n",
    "                                           thresholds=thresholds,\n",
    "                                           figsize=figsize,\n",
    "                                           normalize=normalize_confusion_matrix)\n",
    "\n",
    "                if pred_type == \"Probabilities\":\n",
    "                    self.plot_precision_recall_curve(X,\n",
    "                                                     y,\n",
    "                                                     pred_name=pred_name,\n",
    "                                                     dataset_name=dataset_name,\n",
    "                                                     figsize=figsize,\n",
    "                                                     thresholds=thresholds)\n",
    "                    self.plot_roc_curve(X,\n",
    "                                        y,\n",
    "                                        pred_name=pred_name,\n",
    "                                        dataset_name=dataset_name,\n",
    "                                        figsize=figsize,\n",
    "                                        thresholds=thresholds)\n",
    "\n",
    "                    if self.__binary_classifcation:\n",
    "                        self.plot_lift_curve(X,\n",
    "                                             y,\n",
    "                                             pred_name=pred_name,\n",
    "                                             dataset_name=dataset_name,\n",
    "                                             figsize=figsize,\n",
    "                                             thresholds=thresholds)\n",
    "                        self.plot_ks_statistic(X,\n",
    "                                               y,\n",
    "                                               pred_name=pred_name,\n",
    "                                               dataset_name=dataset_name,\n",
    "                                               figsize=figsize,\n",
    "                                               thresholds=thresholds)\n",
    "                        self.plot_calibration_curve(X,\n",
    "                                                    y,\n",
    "                                                    pred_name=pred_name,\n",
    "                                                    dataset_name=dataset_name,\n",
    "                                                    figsize=figsize,\n",
    "                                                    thresholds=thresholds)\n",
    "                        self.plot_cumulative_gain(X,\n",
    "                                                  y,\n",
    "                                                  pred_name=pred_name,\n",
    "                                                  dataset_name=dataset_name,\n",
    "                                                  figsize=figsize,\n",
    "                                                  thresholds=thresholds)\n",
    "                        \n",
    "                if self.__df_features:\n",
    "                    self.classification_error_analysis(X,\n",
    "                                                       y,\n",
    "                                                       pred_name=pred_name,\n",
    "                                                       dataset_name=dataset_name,\n",
    "                                                       thresholds=thresholds,\n",
    "                                                       display_analysis_graphs=display_analysis_graphs)\n",
    "\n",
    "                    if pred_type == \"Predictions\":\n",
    "                        break\n",
    "\n",
    "    def plot_calibration_curve(self,\n",
    "                               X,\n",
    "                               y,\n",
    "                               pred_name,\n",
    "                               dataset_name,\n",
    "                               thresholds=None,\n",
    "                               save_file=True,\n",
    "                               title=None,\n",
    "                               ax=None,\n",
    "                               cmap='nipy_spectral',\n",
    "                               figsize=None,\n",
    "                               title_fontsize='large',\n",
    "                               text_fontsize='medium'):\n",
    "\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned\n",
    "            stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "        \n",
    "        save_file:\n",
    "            Boolean value to wether or not to save the file. \n",
    "\n",
    "        From scikit-plot documentation (Note not all attributes are provided to you):\n",
    "        Link: http://tinyurl.com/y3ym5pyc\n",
    "        Returns/Descr:\n",
    "            Plots calibration curves for a set of classifier probability estimates.\n",
    "        \"\"\"\n",
    "        \n",
    "        filename = f'KS Statistic on {dataset_name}'\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "        if not title:\n",
    "            title = filename\n",
    "\n",
    "        skplt.metrics.plot_calibration_curve(y,\n",
    "                                             self.__get_model_probas(pred_name,\n",
    "                                                                     X),\n",
    "                                             title=title,\n",
    "                                             ax=ax,\n",
    "                                             cmap=cmap,\n",
    "                                             figsize=figsize,\n",
    "                                             title_fontsize=title_fontsize,\n",
    "                                             text_fontsize=text_fontsize)\n",
    "\n",
    "        if save_file:\n",
    "            create_plt_png(self.get_output_folder(),\n",
    "                           sub_dir,\n",
    "                           convert_to_filename(filename))\n",
    "\n",
    "        if self.__notebook_mode:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_roc_curve(self,\n",
    "                       X,\n",
    "                       y,\n",
    "                       pred_name,\n",
    "                       dataset_name,\n",
    "                       thresholds=None,\n",
    "                       save_file=True,\n",
    "                       title=None,\n",
    "                       ax=None,\n",
    "                       figsize=(10, 8),\n",
    "                       title_fontsize='large',\n",
    "                       text_fontsize='medium'):\n",
    "\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned\n",
    "            stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "        \n",
    "        save_file:\n",
    "            Boolean value to wether or not to save the file. \n",
    "\n",
    "        From scikit-plot documentation (Note not all attributes are provided to you):\n",
    "        Link: http://tinyurl.com/y3ym5pyc\n",
    "        Returns/Descr:\n",
    "            Creates ROC curves from labels and predicted probabilities.\n",
    "        \"\"\"\n",
    "        filename = f'Roc Curve on {dataset_name}'\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "        if not title:\n",
    "            title = filename\n",
    "\n",
    "        skplt.metrics.plot_roc(y,\n",
    "                               self.__get_model_probas(pred_name,\n",
    "                                                       X),\n",
    "                               title=title,\n",
    "                               ax=ax,\n",
    "                               figsize=figsize,\n",
    "                               title_fontsize=title_fontsize,\n",
    "                               text_fontsize=text_fontsize)\n",
    "\n",
    "        if save_file:\n",
    "            create_plt_png(self.get_output_folder(),\n",
    "                           sub_dir,\n",
    "                           convert_to_filename(filename))\n",
    "\n",
    "        if self.__notebook_mode:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_cumulative_gain(self,\n",
    "                             X,\n",
    "                             y,\n",
    "                             pred_name,\n",
    "                             dataset_name,\n",
    "                             thresholds=None,\n",
    "                             save_file=True,\n",
    "                             title=None,\n",
    "                             ax=None,\n",
    "                             figsize=(10, 8),\n",
    "                             title_fontsize='large',\n",
    "                             text_fontsize='medium'):\n",
    "\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned\n",
    "            stored in 'self.__pred_funcs_dict'.\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        save_file:\n",
    "            Boolean value to wether or not to save the file. \n",
    "\n",
    "        From scikit-plot documentation (Note not all attributes are provided to you):\n",
    "        Link: http://tinyurl.com/y3ym5pyc\n",
    "        Returns/Descr:\n",
    "        \"\"\"\n",
    "        filename = f'Cumulative Gain gain on {dataset_name}'\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "        if not title:\n",
    "            title = filename\n",
    "\n",
    "        skplt.metrics.plot_cumulative_gain(y,\n",
    "                                           self.__get_model_probas(pred_name,\n",
    "                                                                   X),\n",
    "                                           title=title,\n",
    "                                           ax=ax,\n",
    "                                           figsize=figsize,\n",
    "                                           title_fontsize=title_fontsize,\n",
    "                                           text_fontsize=text_fontsize)\n",
    "\n",
    "        if save_file:\n",
    "            create_plt_png(self.get_output_folder(),\n",
    "                           sub_dir,\n",
    "                           convert_to_filename(filename))\n",
    "\n",
    "        if self.__notebook_mode:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_precision_recall_curve(self,\n",
    "                                    X,\n",
    "                                    y,\n",
    "                                    pred_name,\n",
    "                                    dataset_name,\n",
    "                                    thresholds=None,\n",
    "                                    save_file=True,\n",
    "                                    title=None,\n",
    "                                    plot_micro=True,\n",
    "                                    classes_to_plot=None,\n",
    "                                    ax=None,\n",
    "                                    figsize=(10, 8),\n",
    "                                    cmap='nipy_spectral',\n",
    "                                    title_fontsize='large',\n",
    "                                    text_fontsize='medium'):\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned\n",
    "            stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        From scikit-plot documentation (Note not all attributes are provided to you):\n",
    "        Link: http://tinyurl.com/y3ym5pyc\n",
    "        Returns/Descr:\n",
    "            Creates a plot precision recall curve plot based on the models predictions.\n",
    "        \"\"\"\n",
    "\n",
    "        filename = f'Precision Recall on {dataset_name}'\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "        if not title:\n",
    "            title = filename\n",
    "\n",
    "        skplt.metrics.plot_precision_recall(y,\n",
    "                                            self.__get_model_probas(pred_name,\n",
    "                                                                    X),\n",
    "                                            title=title,\n",
    "                                            plot_micro=plot_micro,\n",
    "                                            classes_to_plot=classes_to_plot,\n",
    "                                            ax=ax,\n",
    "                                            figsize=figsize,\n",
    "                                            cmap=cmap,\n",
    "                                            title_fontsize=title_fontsize,\n",
    "                                            text_fontsize=text_fontsize)\n",
    "\n",
    "        if save_file:\n",
    "            create_plt_png(self.get_output_folder(),\n",
    "                           sub_dir,\n",
    "                           convert_to_filename(filename))\n",
    "\n",
    "        if self.__notebook_mode:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_lift_curve(self,\n",
    "                        X,\n",
    "                        y,\n",
    "                        pred_name,\n",
    "                        dataset_name,\n",
    "                        thresholds=None,\n",
    "                        save_file=True,\n",
    "                        title=None,\n",
    "                        ax=None,\n",
    "                        figsize=(10, 8),\n",
    "                        title_fontsize='large',\n",
    "                        text_fontsize='medium'):\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned\n",
    "            stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        From scikit-plot documentation (Note not all attributes are provided to you):\n",
    "        Link: http://tinyurl.com/y3ym5pyc\n",
    "        Returns/Descr:\n",
    "            Creates a plot precision recall curve plot based on the models predictions.\n",
    "        \"\"\"\n",
    "\n",
    "        filename = f'Lift Curve on {dataset_name}'\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "        if not title:\n",
    "            title = filename\n",
    "\n",
    "        skplt.metrics.plot_lift_curve(y,\n",
    "                                      self.__get_model_probas(pred_name,\n",
    "                                                              X),\n",
    "                                      thresholds=thresholds,\n",
    "                                      title=title,\n",
    "                                      ax=ax,\n",
    "                                      figsize=figsize,\n",
    "                                      title_fontsize=title_fontsize,\n",
    "                                      text_fontsize=text_fontsize)\n",
    "        if save_file:\n",
    "            create_plt_png(self.get_output_folder(),\n",
    "                           sub_dir,\n",
    "                           convert_to_filename(filename))\n",
    "\n",
    "        if self.__notebook_mode:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_confusion_matrix(self,\n",
    "                              X,\n",
    "                              y,\n",
    "                              pred_name,\n",
    "                              dataset_name,\n",
    "                              thresholds=None,\n",
    "                              save_file=True,\n",
    "                              title=None,\n",
    "                              normalize=False,\n",
    "                              hide_zeros=False,\n",
    "                              hide_counts=False,\n",
    "                              x_tick_rotation=0,\n",
    "                              ax=None,\n",
    "                              figsize=(10, 8),\n",
    "                              cmap='Blues',\n",
    "                              title_fontsize='large',\n",
    "                              text_fontsize='medium'):\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned\n",
    "            stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        From scikit-plot documentation (Note not all attributes are provided to you):\n",
    "        Link: http://tinyurl.com/y3ym5pyc\n",
    "        Returns/Descr:\n",
    "            Creates a confusion matrix plot based on the models predictions.\n",
    "        \"\"\"\n",
    "        filename = f'Confusion Matrix: {dataset_name}'\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "        if not title:\n",
    "            title = filename\n",
    "\n",
    "        warnings.filterwarnings('ignore')\n",
    "        skplt.metrics.plot_confusion_matrix(\n",
    "            self.__get_model_prediction(pred_name,\n",
    "                                        X,\n",
    "                                        thresholds),\n",
    "            y,\n",
    "            title=title,\n",
    "            normalize=normalize,\n",
    "            hide_zeros=hide_zeros,\n",
    "            hide_counts=hide_counts,\n",
    "            x_tick_rotation=x_tick_rotation,\n",
    "            ax=ax,\n",
    "            figsize=figsize,\n",
    "            cmap=cmap,\n",
    "            title_fontsize=title_fontsize,\n",
    "            text_fontsize=text_fontsize)\n",
    "        warnings.filterwarnings('default')\n",
    "\n",
    "        if save_file:\n",
    "            create_plt_png(self.get_output_folder(),\n",
    "                           sub_dir,\n",
    "                           convert_to_filename(filename))\n",
    "\n",
    "        if self.__notebook_mode:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def classification_metrics(self,\n",
    "                               X,\n",
    "                               y,\n",
    "                               pred_name,\n",
    "                               dataset_name,\n",
    "                               thresholds=None,\n",
    "                               save_file=True,\n",
    "                               title=\"\",\n",
    "                               custom_metrics=dict(),\n",
    "                               ignore_metrics=[],\n",
    "                               average_scoring=[\"micro\",\n",
    "                                                \"macro\",\n",
    "                                                \"weighted\"]):\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned stored\n",
    "            in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        save_file:\n",
    "            Determines whether or not to save the generated document.\n",
    "\n",
    "        title:\n",
    "            Adds to the column 'Metric Score'.\n",
    "\n",
    "        sub_dir:\n",
    "            Specify a subdirectory to append to the output path of the file.\n",
    "\n",
    "        custom_metrics:\n",
    "            Pass the name of metric(s) and the function definition(s) in a\n",
    "            dictionary.\n",
    "\n",
    "        ignore_metrics:\n",
    "            Specify the default metrics to not apply to the classification\n",
    "            analysis.\n",
    "                * Precision\n",
    "                * MCC\n",
    "                * Recall\n",
    "                * F1-Score\n",
    "                * Accuracy\n",
    "\n",
    "        average_scoring:\n",
    "            Determines the type of averaging performed on the data.\n",
    "                * micro\n",
    "                * macro\n",
    "                * weighted\n",
    "\n",
    "        Returns/Desc:\n",
    "            Creates/displays a dataframe object based on the model's\n",
    "            predictions on the feature matrix compared to target data.\n",
    "        \"\"\"\n",
    "        filename = f'Metric Evaluation on {dataset_name}'\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "\n",
    "        if not isinstance(average_scoring, list):\n",
    "            average_scoring = [average_scoring]\n",
    "\n",
    "        # Default metric name's and their function\n",
    "        metric_functions = dict()\n",
    "        metric_functions[\"Precision\"] = precision_score\n",
    "        metric_functions[\"MCC\"] = matthews_corrcoef\n",
    "        metric_functions[\"Recall\"] = recall_score\n",
    "        metric_functions[\"F1-Score\"] = f1_score\n",
    "        metric_functions[\"Accuracy\"] = accuracy_score\n",
    "\n",
    "        warnings.filterwarnings('ignore')\n",
    "\n",
    "        # Ignore default metrics if needed\n",
    "        for remove_metric in ignore_metrics:\n",
    "            if remove_metric in metric_functions:\n",
    "                del metric_functions[remove_metric]\n",
    "\n",
    "        # Add in custom metrics\n",
    "        if len(custom_metrics.keys()):\n",
    "            metric_functions.update(custom_metrics)\n",
    "\n",
    "        # Evaluate model on metrics\n",
    "        evaluation_report = dict()\n",
    "        for metric_name in metric_functions:\n",
    "            for average_score in average_scoring:\n",
    "\n",
    "                model_predictions = self.__get_model_prediction(pred_name,\n",
    "                                                                X,\n",
    "                                                                thresholds)\n",
    "                try:\n",
    "                    evaluation_report[f'{metric_name}({average_score})'] = \\\n",
    "                        metric_functions[metric_name](y_true=y,\n",
    "                                                      y_pred=model_predictions,\n",
    "                                                      average=average_score)\n",
    "                except TypeError:\n",
    "                    evaluation_report[metric_name] = metric_functions[\n",
    "                        metric_name](y,\n",
    "                                     model_predictions)\n",
    "                    break\n",
    "\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        warnings.filterwarnings('default')\n",
    "\n",
    "        if title and len(title) > 0:\n",
    "            index_name = f\"Metric Scores ({title})\"\n",
    "        else:\n",
    "            index_name = \"Metric Scores\"\n",
    "\n",
    "        # ---\n",
    "        evaluation_report = pd.DataFrame({index_name:\n",
    "                                              [f'{metric_score:.4f}'\n",
    "                                               for metric_score\n",
    "                                               in evaluation_report.values()]},\n",
    "                                         index=list(evaluation_report.keys()))\n",
    "\n",
    "        if self.__notebook_mode:\n",
    "            display(evaluation_report)\n",
    "        else:\n",
    "            print(evaluation_report)\n",
    "\n",
    "        if save_file:\n",
    "            # Create image file\n",
    "            df_to_image(evaluation_report,\n",
    "                        self.get_output_folder(),\n",
    "                        sub_dir,\n",
    "                        convert_to_filename(filename),\n",
    "                        col_width=20,\n",
    "                        show_index=True,\n",
    "                        format_float_pos=4)\n",
    "\n",
    "    def classification_error_analysis(self,\n",
    "                                      X,\n",
    "                                      y,\n",
    "                                      pred_name,\n",
    "                                      dataset_name,\n",
    "                                      thresholds=None,\n",
    "                                      save_file=True,\n",
    "                                      display_analysis_graphs=False):\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned\n",
    "            stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        save_file:\n",
    "            Determines whether or not to save the generated document.\n",
    "            \n",
    "        display_analysis_graphs:\n",
    "            Controls visual display of graph generation.\n",
    "\n",
    "        Returns/Descr:\n",
    "            Creates a directory structure of subsetted data produced by all correctly/predicted.\n",
    "        \"\"\"\n",
    "\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "\n",
    "        model_predictions = self.__get_model_prediction(pred_name,\n",
    "                                                        X,\n",
    "                                                        thresholds=thresholds)\n",
    "\n",
    "        if sum(model_predictions == y):\n",
    "            if display_analysis_graphs:\n",
    "                print(\"\\n\\n\" + \"*\" * 10 +\n",
    "                      \"Correctly predicted analysis\"\n",
    "                      + \"*\" * 10 + \"\\n\")\n",
    "            else:\n",
    "                print(\"\\n\\n\" + \"*\" * 10 +\n",
    "                      \"Generating graphs for model's correctly predicted...\" +\n",
    "                      \"*\" * 10 + \"\\n\")\n",
    "                DataAnalysis(pd.DataFrame(X[model_predictions == y],\n",
    "                                          columns=self.__df_features.get_all_features()),\n",
    "                             self.__df_features,\n",
    "                             overwrite_full_path=self.get_output_folder() +\n",
    "                                                 sub_dir + \"/Correctly Predicted Data/\",\n",
    "                             missing_data_visuals=False,\n",
    "                             notebook_mode=display_analysis_graphs)\n",
    "        else:\n",
    "            print(\"Your model predicted nothing correctly...dam that sucks\")\n",
    "\n",
    "        if sum(model_predictions != y):\n",
    "            if display_analysis_graphs:\n",
    "                print(\"\\n\\n\" + \"*\" * 10 +\n",
    "                      \"Incorrectly predicted analysis\"\n",
    "                      + \"*\" * 10 + \"\\n\")\n",
    "            else:\n",
    "                print(\"\\n\\n\" + \"*\" * 10 +\n",
    "                      \"Generating graphs for model's incorrectly predicted...\" +\n",
    "                      \"*\" * 10 + \"\\n\")\n",
    "            \n",
    "#             for target_value in self.__target_values:\n",
    "                \n",
    "\n",
    "            DataAnalysis(pd.DataFrame(X[model_predictions != y],\n",
    "                                      columns=self.__df_features.get_all_features()),\n",
    "                         self.__df_features,\n",
    "                         overwrite_full_path=self.get_output_folder() +\n",
    "                                             sub_dir + \"/Incorrectly Predicted Data/\",\n",
    "                         missing_data_visuals=False,\n",
    "                         notebook_mode=display_analysis_graphs)\n",
    "        else:\n",
    "            print(\n",
    "                \"\\n\\nYour model predicted everything correctly...there is something very wrong here...\")\n",
    "\n",
    "    def classification_report(self,\n",
    "                              X,\n",
    "                              y,\n",
    "                              pred_name,\n",
    "                              dataset_name,\n",
    "                              thresholds=None,\n",
    "                              save_file=True):\n",
    "        \"\"\"\n",
    "        X/y:\n",
    "            Feature matrix/Target data vector.\n",
    "\n",
    "        pred_name:\n",
    "            The name of the prediction function in questioned\n",
    "            stored in 'self.__pred_funcs_dict'\n",
    "\n",
    "        dataset_name:\n",
    "            The dataset's name.\n",
    "\n",
    "        thresholds:\n",
    "            If the model outputs a probability list/numpy array then we apply\n",
    "            thresholds to the ouput of the model.\n",
    "            For classification only; will not affect the direct output of\n",
    "            the probabilities.\n",
    "\n",
    "        save_file:\n",
    "            Determines whether or not to save the generated document.\n",
    "\n",
    "        Returns/Descr:\n",
    "            Creates a report of all target's metric evaluations\n",
    "            based on the model's prediction output.\n",
    "        \"\"\"\n",
    "        filename = f'Classification Report {dataset_name}'\n",
    "        sub_dir = self.__create_sub_dir_with_thresholds(pred_name,\n",
    "                                                        dataset_name,\n",
    "                                                        thresholds)\n",
    "\n",
    "        # Create dataframe report\n",
    "        report_df = pd.DataFrame(classification_report(y,\n",
    "                                                       self.__get_model_prediction(\n",
    "                                                           pred_name,\n",
    "                                                           X,\n",
    "                                                           thresholds),\n",
    "                                                       output_dict=True))\n",
    "\n",
    "        # ---\n",
    "        if self.__notebook_mode:\n",
    "            display(report_df)\n",
    "        else:\n",
    "            print(report_df)\n",
    "\n",
    "        if save_file:\n",
    "            # Output dataframe as png\n",
    "            df_to_image(report_df,\n",
    "                        self.get_output_folder(),\n",
    "                        sub_dir,\n",
    "                        filename,\n",
    "                        col_width=20,\n",
    "                        show_index=True,\n",
    "                        format_float_pos=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_analysis = ClassificationAnalysis(model=model,\n",
    "                                     pred_funcs_dict={\"Probabilities function\":model.predict_proba,\n",
    "                                                      \"Predict function\":model.predict},\n",
    "                                     sample_data=X_train,\n",
    "                                     model_name=repr(model).split(\"(\")[0],\n",
    "                                     project_name=f'{parent_project_name}/Classification Analysis',\n",
    "                                     notebook_mode=True,\n",
    "                                     df_features=df_features)\n",
    "\n",
    "dt_analysis.perform_analysis(X=X_train,\n",
    "                             y=y_train,\n",
    "                             dataset_name=\"Training Data\",\n",
    "                             thresholds_matrix=[[.2,.2,.2,.2,.2,.2,.2,.2,.2,.2,.2],\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(\"/Users/ericcacciavillani/Desktop/Coding/Python_Files/Artificial_Intelligence/Data Mining/eFlowMaster/Testing/eFlow Data/Pre processing/Supervised Analysis/DecisionTreeClassifier/Probabilities function/Thresholds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_unique_directory_path(os.getcwd() + \"/eFlow Data/Pre processing/Supervised Analysis/DecisionTreeClassifier/Test data/Probability Classification/\",\n",
    "                        \"Model Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_string = os.getcwd().replace(\"/\", \"///\")\n",
    "error_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = \"/Users/ericcacciavillani/Desktop/Coding/Python_Files/Artificial_Intelligence/Data Mining/eFlowMaster/Testing/eFlow Data/Pre processing/Supervised Analysis/DecisionTreeClassifier/Test data/Probability Classification\"\n",
    "correct_directory_path(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[[1,2],[1,2,3],[1]]\n",
    "c = copy.deepcopy(a)\n",
    "b=np.array(a)\n",
    "b.tolist()\n",
    "hhh = None\n",
    "if hhh:\n",
    "    print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb = None\n",
    "\n",
    "if not bbb:\n",
    "    print(\"test\")\n",
    "else:\n",
    "    print(\"fff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_y = copy.deepcopy(y_test)\n",
    "vector_y = np.where(vector_y==0, \"Test\", vector_y) \n",
    "vector_y = np.where(vector_y=='1', \"Blarg\", vector_y)\n",
    "vector_y = np.where(vector_y=='2', \"Dragon\", vector_y)\n",
    "vector_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(vector_y, vector_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0, 0, 8.3, 0, 0, 0, 0, 0, 0, 0, .36]\n",
    "\n",
    "model_output = model.predict_proba(X_train)\n",
    "\n",
    "print(model_output)\n",
    "# Validate probabilities\n",
    "if thresholds:\n",
    "    if isinstance(thresholds, list) or \\\n",
    "            isinstance(thresholds, np.ndarray):\n",
    "        if sum(thresholds) < .98:\n",
    "            print(\"Thresholds didn't add up to 98%-100%! \"\n",
    "                  \"This may cause issues in your results!\")\n",
    "    else:\n",
    "        raise ThresholdType\n",
    "\n",
    "# ---\n",
    "if isinstance(model_output, list):\n",
    "    model_output = np.asarray(model_output)\n",
    "\n",
    "if isinstance(model_output, np.ndarray):\n",
    "    if thresholds:\n",
    "        outputs_passed_threshold = model_output > np.asarray(thresholds)\n",
    "outputs_passed_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "class UnExpectedData(UserWarning, ValueError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = model.predict_proba(X_train)\n",
    "bool_matrix_thresholds = model_output < np.asarray([.2,.2,.2,.2,.2,.2,.2,.2,.2,.2,.2])\n",
    "\n",
    "tmp_matrix = []\n",
    "for bool_vector in bool_matrix_thresholds:\n",
    "    tmp_vector = []\n",
    "    for i,passed in enumerate(bool_vector):\n",
    "        if passed:\n",
    "            tmp_vector.append(model_output[i][0])\n",
    "        else:\n",
    "            tmp_vector.append(float(\"-inf\"))\n",
    "    tmp_matrix.append(tmp_vector)\n",
    "print(tmp_matrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = msno.bar(df[df.columns[df.isna().any()].tolist()],\n",
    "              color=\"#072F5F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.isnull().sum().index.tolist()\n",
    "null_values = df.isnull().sum().values.tolist()\n",
    "null_sorted_features, null_values = zip(*sorted(zip(null_values,\n",
    "                                                    features)))\n",
    "\n",
    "for feature_index, value in enumerate(null_values):\n",
    "    if value == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eflow._hidden.utils.meta_data_identity import check_create_metadata_of_dataframe\n",
    "testing_path = \"/Users/ericcacciavillani/Desktop/Coding/Python_Files/Artificial_Intelligence/Data Mining/eFlowMaster/Testing/eflow Data/Pre processing/Missing Data/All Data\"\n",
    "check_create_metadata_of_dataframe(df,\n",
    "                                   testing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "feature_name = \"Feature_name\"\n",
    "for hash_type in [1,2,3,4,5,6,7,8,9,10]:\n",
    "    result = 0\n",
    "    for char_index, char in enumerate(feature_name):\n",
    "        if hash_type == 1:\n",
    "            result += int(ord(char))\n",
    "        elif hash_type == 2:\n",
    "            result += int(ord(char) + 62 * ord(char))\n",
    "        elif hash_type == 3:\n",
    "            result += int(ord(char) + 147 * ord(char))\n",
    "        elif hash_type == 4:\n",
    "            result += int((ord(char) + 92) * math.pow(ord(char), 3))\n",
    "        elif hash_type == 5:\n",
    "            result += int(ord(char) + 49 * math.pow(ord(char), 2))\n",
    "        elif hash_type == 6:\n",
    "            result += int((23 + ord(char) + 45) * (3 + ord(char) + 2))\n",
    "        elif hash_type == 7:\n",
    "            result += int((ord(char) * 5) + 32 + 8)\n",
    "        elif hash_type == 8:\n",
    "            result += int(math.pow(ord(char), 2))\n",
    "        elif hash_type == 9:\n",
    "            result += int(ord(char) * 2 + 32 + ord(char) * 2 + 5)\n",
    "        elif hash_type == 10:\n",
    "            result += int(ord(char) * 12 + 76 + math.pow(ord(char), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Ticket\"][891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1,2,3]) % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Age\" in {'Aged', 'Fare'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
