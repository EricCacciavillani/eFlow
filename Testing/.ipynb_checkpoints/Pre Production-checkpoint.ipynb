{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from eFlow.ClusterMaster import *\n",
    "from eFlow.DataFrameTypes import *\n",
    "from eFlow.Analysis.DataAnalysis import *\n",
    "from eFlow.PipelineSegments.DataCleaner import *\n",
    "from xgboost import XGBClassifier\n",
    "import ipython_blocking\n",
    "from pivottablejs import pivot_ui\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be sure to run the following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Worflow Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (This should be the only place you should have to declare anything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"Datasets/titanic_train.csv\"\n",
    "target_column = \"Survived\"\n",
    "parent_project_name = \"Pre processing\"\n",
    "prediction_method = \"Classification\"\n",
    "notebook_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path)\n",
    "display(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction tool for dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_ui(df,\n",
    "         outfile_path='Piviot_Table_JS.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = widgets.SelectMultiple(\n",
    "#     options=['Apples', 'Oranges', 'Pears'],\n",
    "#     value=['Oranges'],\n",
    "#     #rows=10,\n",
    "#     description='Fruits',\n",
    "#     disabled=False\n",
    "# )\n",
    "# del w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = str(u\"\\u2192\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Un-Wanted Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do not remove nans yet, let the datacleaner do it's job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Name\",\n",
    "                 \"Ticket\",\n",
    "                 \"PassengerId\"],\n",
    "        inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "dt = parser.parse(\"Aug 28 1999 12:00AM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date_test\"] = [\"2019-01-02\" for _ in range(0,df.shape[0])]\n",
    "df[\"Date_test\"][0] = np.nan\n",
    "# df[\"Date_test\"] = [parser.parse(val)for val in df[\"Date_test\"].value_counts().keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Feature manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change cabin column to have the level on the ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cabin\"] = df[\"Cabin\"].str.replace(r'\\d+', '').str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Feature Data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make given data type changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Pclass\"] = df[\"Pclass\"].replace(1, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final look at data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up DataFrameTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = DataFrameTypes(df,\n",
    "                             target_column=target_column,\n",
    "                             ignore_nulls=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skim through Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col not in df_features.get_float_features() and len(np.unique(df[col].dropna().values)) <= 12:\n",
    "        display(df[col].value_counts())\n",
    "        print(\"***\" * 4 + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform quick analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_obj = DataAnalysis(df,\n",
    "                            df_features,\n",
    "                            project_name=parent_project_name + \"/\" + \"General Analysis (Before Cleaning)\",\n",
    "                            missing_data_visuals=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner = DataCleaner(df,\n",
    "                           project_name=parent_project_name + \"/\" + \"Data Cleaning\",\n",
    "                           missing_data_visuals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner.data_cleaning_widget(df,\n",
    "                                  df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner.get_last_saved_json_file_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner.data_cleaning_with_json_file(df,\n",
    "                                          data_cleaner.get_last_saved_json_file_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "df.reset_index(drop=True)\n",
    "z_score_return = stats.zscore(((df[\"Age\"].dropna())))\n",
    "df[\"Age\"].dropna()[(z_score_return >= -2) & (z_score_return <= 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from impyute.imputation.cs import mice\n",
    "\n",
    "a = df[\"Age\"].tolist()\n",
    "# start the MICE training\n",
    "imputed_training=mice(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datawig\n",
    "\n",
    "df_train, df_test = datawig.utils.random_split(df)\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer = datawig.SimpleImputer(\n",
    "    input_columns=['Survived', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Fare', 'Cabin','Embarked'], # column(s) containing information about the column we want to impute\n",
    "    output_column= 'Age', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer.fit(train_df=df, num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_training=mice(df[df_features.get_numerical_features()].values)\n",
    "imputed_training[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datawig\n",
    "# !pip install opencv-python\n",
    "# !pip install Pillow\n",
    "# !pip install tesserocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "test = df.drop(columns=[\"Sex\", \"Date_test\", \"Embarked\", \"Cabin\"]).dropna()\n",
    "\n",
    "test[target_column] = [random.randint(0, 40) for _ in range(0,test.shape[0])]\n",
    "print(len(test[target_column]))\n",
    "\n",
    "y = test[target_column].values\n",
    "X = test.values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=5187\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from eFlow.ToolBox.Modeling import *\n",
    "# Find best parameters for model\n",
    "param_grid = {\n",
    "    \"max_depth\": list(range(2, 8)),\n",
    "    \"min_samples_leaf\": list(range(1, 35, 5)),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "#     \"n_splits\": [10]\n",
    "}\n",
    "\n",
    "model, best_params = optimize_model_grid(\n",
    "    model=DecisionTreeClassifier(),\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    param_grid=param_grid\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eFlow._Hidden.Objects.enum import enum\n",
    "from eFlow.Utils.SysUtils import *\n",
    "from eFlow.Utils.Constants import *\n",
    "\n",
    "class SupervisedAnalysis:\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 X_train,\n",
    "                 X_test,\n",
    "                 y_train,\n",
    "                 y_test,\n",
    "                 model_name,\n",
    "                 prediction_type=\"Classification\",\n",
    "                 project_name=\"Supervised Analysis\",\n",
    "                 overwrite_full_path=None,\n",
    "                 notebook_mode=True,\n",
    "                 normalize_confusion_matrix=True):\n",
    "        \n",
    "        # Init objectss by pass by refrence\n",
    "#         self.__X_train = X_train\n",
    "#         self.__X_test = X_test\n",
    "#         self.__y_train = y_train\n",
    "#         self.__y_test = y_test\n",
    "        self.__model = model\n",
    "        self.__model_name = copy.deepcopy(model_name)\n",
    "        self.__notebook_mode = notebook_mode\n",
    "        \n",
    "#         skplt.metrics.plot_roc(y_train, y_train)\n",
    "\n",
    "        # Setup project structure\n",
    "        if not overwrite_full_path:\n",
    "            parent_structure = \"/\" + SYS_CONSTANTS.PARENT_OUTPUT_FOLDER_NAME \\\n",
    "                               + \"/\" + project_name + \"/\"\n",
    "            self.__PROJECT = enum(PATH_TO_OUTPUT_FOLDER=\n",
    "                                  os.getcwd() + parent_structure)\n",
    "        else:\n",
    "            self.__PROJECT = enum(PATH_TO_OUTPUT_FOLDER=overwrite_full_path)\n",
    "        \n",
    "        if prediction_type == \"Classifcation\":\n",
    "            \n",
    "            self.confusion_matrix(X_train,\n",
    "                                  y_train,\n",
    "                                  title=\"Confusion Matrix: Training Data\",\n",
    "                                  normalize=normalize_confusion_matrix)\n",
    "            \n",
    "            self.confusion_matrix(X_test,\n",
    "                                  y_test,\n",
    "                                  title=\"Confusion Matrix: Testing Data\",\n",
    "                                  normalize=normalize_confusion_matrix)\n",
    "            \n",
    "            if len(set(y_train) | set(y_test)) == 2:\n",
    "                self.__binary_classification = True\n",
    "            else:\n",
    "                self.__binary_classification = False\n",
    "\n",
    "            try:\n",
    "                y_probas = model.predict_proba(X_test)\n",
    "                skplt.metrics.plot_roc(y_test, y_probas,figsize=(10,8))\n",
    "                \n",
    "                if self.__binary_classification:\n",
    "                    skplt.metrics.plot_ks_statistic(y_test, y_probas,figsize=(10,8))\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            \n",
    "        elif prediction_type == \"Regression\":\n",
    "            pass\n",
    "        else:\n",
    "            print(\"ERROR\")\n",
    "        \n",
    "    def confusion_matrix(self,\n",
    "                         X,\n",
    "                         y,\n",
    "                         figsize=(10,8),\n",
    "                         title=None,\n",
    "                         filename=None,\n",
    "                         normalize=True):\n",
    "        \n",
    "        if title:\n",
    "            skplt.metrics.plot_confusion_matrix(self.__model.predict(X),\n",
    "                                                y,\n",
    "                                                figsize=figsize,\n",
    "                                                title=title,\n",
    "                                                normalize=normalize)\n",
    "        else:\n",
    "            skplt.metrics.plot_confusion_matrix(self.__model.predict(X),\n",
    "                                                y,\n",
    "                                                figsize=figsize,\n",
    "                                                normalize=normalize)\n",
    "        if filename:\n",
    "            create_plt_png(self.__PROJECT.PATH_TO_OUTPUT_FOLDER,\n",
    "                           self.__model_name,\n",
    "                           filename)\n",
    "        elif filename is None and title:\n",
    "            create_plt_png(self.__PROJECT.PATH_TO_OUTPUT_FOLDER,\n",
    "                           self.__model_name,\n",
    "                           convert_to_file_name(title.replace(\":\", \"\").replace(\" \", \"_\")))\n",
    "        else:\n",
    "            create_plt_png(self.__PROJECT.PATH_TO_OUTPUT_FOLDER,\n",
    "                           self.__model_name,\n",
    "                           \"Confusion_Matrix\")\n",
    "            \n",
    "        if self.__notebook_mode:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "SupervisedAnalysis(model=model,\n",
    "                   model_name=repr(model).split(\"(\")[0],\n",
    "                   X_train=X_train,\n",
    "                   X_test=X_test,\n",
    "                   y_train=y_train,\n",
    "                   y_test=y_test,\n",
    "                   project_name=parent_project_name + \"/\" + \"SupervisedAnalysis\",\n",
    "                   prediction_type=\"Classifcation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.DataFrame(classification_report(y_test,\n",
    "                                            model.predict(X_test),output_dict=True))\n",
    "report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df.values[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
