{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the markdown blocks that say interaction required! The notebook should take care of the rest!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyclustering'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0427c8c541e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meflow_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_type_holder_from_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_unconnected_pipeline_segments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_types_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0meflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_modeler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoCluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Coding/Python_Files/Artificial_Intelligence/Data Mining/eFlow/eflow/auto_modeler/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcluster_master\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoCluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Coding/Python_Files/Artificial_Intelligence/Data Mining/eFlow/eflow/auto_modeler/cluster_master.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Getting pyclustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkmeans\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter_initializer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkmeans_plusplus_initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyclustering'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "from eflow.foundation import DataPipeline,DataFrameTypes\n",
    "from eflow.model_analysis import ClassificationAnalysis\n",
    "from eflow.utils.modeling_utils import optimize_model_grid\n",
    "from eflow.utils.eflow_utils import get_type_holder_from_pipeline, remove_unconnected_pipeline_segments\n",
    "from eflow.utils.pandas_utils import data_types_table\n",
    "from eflow.auto_modeler import AutoCluster\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import pickle\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Additional add ons\n",
    "# !pip install pandasgui\n",
    "# !pip install pivottablejs\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Project Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"Datasets/titanic_train.csv\"\n",
    "\n",
    "# -----\n",
    "dataset_name = \"Titanic Data\"\n",
    "pipeline_name = \"Titanic Pipeline\"\n",
    "\n",
    "# -----\n",
    "\n",
    "\n",
    "# -----\n",
    "notebook_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean out segment space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_unconnected_pipeline_segments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path)\n",
    "shape_df = pd.DataFrame.from_dict({'Rows': [df.shape[0]],\n",
    "                                   'Columns': [df.shape[1]]})\n",
    "display(shape_df)\n",
    "display(df.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and init df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option: 1\n",
    "# df_features = get_type_holder_from_pipeline(pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option: 2\n",
    "df_features = DataFrameTypes()\n",
    "df_features.init_on_json_file(os.getcwd() + f\"/eflow Data/{dataset_name}/df_features.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.display_features(display_dataframes=True,\n",
    "                             notebook_mode=notebook_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Any extra processing before eflow DataPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup pipeline structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipe = DataPipeline(pipeline_name,\n",
    "                         df,\n",
    "                         df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipe.perform_pipeline(df,\n",
    "                           df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate clustering models with automodeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_cluster = AutoCluster(df,\n",
    "                           df_features,\n",
    "                           project_sub_dir=dataset_name,\n",
    "                           overwrite_full_path=None,\n",
    "                           notebook_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporialy remove dataframe to save RAM for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Hierarchical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto_cluster.visualize_hierarchical_clustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_cluster.create_kmeans_models_with_elbow_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError(\"Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.init_on_json_file(os.getcwd() + f\"/eflow Data/{dataset_name}/df_features.json\")\n",
    "df_features.display_features(display_dataframes=True,\n",
    "                             notebook_mode=notebook_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipe.perform_pipeline(df,\n",
    "                           df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import DataGenerator, KneeLocator\n",
    "\n",
    "x = [5346.0, 4464.47220442314, 3650.8164825776444, 2883.4865344266404, 2353.5226410046207, 1923.7811636297681, 1668.8974296738902, 1472.2444437394222, 1280.4754069907601, 1149.2682037351174, 1057.4340058596358, 959.3105185259967, 881.3187084234528, 806.0797704821307]\n",
    "kneedle = KneeLocator(x, [i for i in range(0,len(x))], curve='concave', direction='increasing', interp_method='polynomial', online=True)\n",
    "\n",
    "# average knee point\n",
    "print(kneedle.knee)\n",
    "round(sum(knees) / len(knees), 3)\n",
    "63.583"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias = [5346.0, 4464.47220442314, 3650.8164825776444]\n",
    "inertias_matrix = np.matrix(inertias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias_matrix = np.vstack([inertias_matrix, [5000, 4000, 3680]])\n",
    "inertias_matrix = np.vstack([inertias_matrix, [7000, 6000, 4680]])\n",
    "inertias_matrix = np.vstack([inertias_matrix, [5700, 5300, 4680]])\n",
    "\n",
    "inertias_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_elbow_inertias = inertias_matrix.mean(0)\n",
    "average_elbow_inertias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_vote = []\n",
    "\n",
    "for vector in inertias_matrix:\n",
    "    knee_vote.append(np.absolute(vector - average_elbow_inertias).sum())\n",
    "\n",
    "best_elbow_index = np.array(knee_vote).argmin()\n",
    "best_of_elbows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kmeans_models_with_elbow_graph(self,\n",
    "                                          random_state=None):\n",
    "    \"\"\"\n",
    "        Generate models based on the found 'elbow' of the interia values.\n",
    "    \"\"\"\n",
    "\n",
    "    elbow_inertias_matrix = None\n",
    "    inertias_matrix = None\n",
    "    elbow_models = []\n",
    "    plt.figure(figsize=(13, 6))\n",
    "    plt.title(\"All possible Kmeans Elbow's\", fontsize=15)\n",
    "    plt.xlabel('Number of clusters, k')\n",
    "    plt.ylabel('Inertia')\n",
    "    ks = range(1, 15)\n",
    "    plt.xticks(ks)\n",
    "\n",
    "    for i in range(0,200):\n",
    "\n",
    "        inertias = []\n",
    "        k_models = []\n",
    "\n",
    "        for k in ks:\n",
    "            # Create a KMeans instance with k clusters: model\n",
    "            model = KMeans(n_clusters=k,\n",
    "                           random_state=random_state).fit(self.__scaled)\n",
    "\n",
    "            # Append the inertia to the list of inertias\n",
    "            inertias.append(model.inertia_)\n",
    "            k_models.append(model)\n",
    "\n",
    "        # Plot ks vs inertias\n",
    "        plt.plot(ks,\n",
    "                 inertias,\n",
    "                 '-o',\n",
    "                 color='#367588')\n",
    "\n",
    "        elbow_cluster = KneeLocator([i for i in range(1,\n",
    "                                          len(inertias) + 1)],\n",
    "                                  inertias,\n",
    "                                  curve='convex',\n",
    "                                  direction='decreasing').knee\n",
    "\n",
    "        for k_val in [elbow_cluster - 1, elbow_cluster, elbow_cluster + 1]:\n",
    "            plt.plot(ks[k_val - 1], inertias[k_val - 1], 'r*')\n",
    "\n",
    "        elbow_models.append(k_models[elbow_cluster - 2:elbow_cluster + 1])\n",
    "\n",
    "        if isinstance(elbow_inertias_matrix,type(None)):\n",
    "            inertias_matrix = np.matrix(inertias)\n",
    "            inertias = inertias[k_val - 2: k_val + 1]\n",
    "\n",
    "            elbow_inertias_matrix = np.matrix(inertias)\n",
    "\n",
    "        else:\n",
    "            inertias_matrix = np.vstack([inertias_matrix, inertias])\n",
    "            inertias = inertias[k_val - 2: k_val + 1]\n",
    "\n",
    "            elbow_inertias_matrix = np.vstack([elbow_inertias_matrix, inertias])\n",
    "\n",
    "        del inertias\n",
    "        del k_models\n",
    "        del elbow_cluster\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    plt.figure(figsize=(13, 6))\n",
    "    plt.title(\"Best of all Kmeans Elbow\", fontsize=15)\n",
    "    plt.xlabel('Number of clusters, k')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.xticks(ks)\n",
    "\n",
    "    average_elbow_inertias = elbow_inertias_matrix.mean(0)\n",
    "\n",
    "    knee_vote = []\n",
    "    for vector in elbow_inertias_matrix:\n",
    "        knee_vote.append(\n",
    "            np.absolute(vector - average_elbow_inertias).sum())\n",
    "\n",
    "    best_elbow_index = np.array(knee_vote).argmin()\n",
    "\n",
    "    plt.plot(ks,\n",
    "             inertias_matrix[best_elbow_index].tolist()[0],\n",
    "             '-o',\n",
    "             color='#367588')\n",
    "\n",
    "\n",
    "    for model in elbow_models[best_elbow_index]:\n",
    "        k_val = model.n_clusters\n",
    "        self.__all_cluster_models[\"Kmeans_Cluster_\" + str(k_val)] = model\n",
    "        plt.plot(ks[k_val - 1], inertias_matrix[best_elbow_index].tolist()[0][k_val - 1], 'r*')\n",
    "\n",
    "        # print(\"Successfully generate Kmeans model on k_val={0}\".format(k_val))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
