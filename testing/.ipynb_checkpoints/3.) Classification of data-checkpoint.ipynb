{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the markdown blocks that say interaction required! The notebook should take care of the rest!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "from eflow.foundation import DataPipeline,DataFrameTypes\n",
    "from eflow.model_analysis import ClassificationAnalysis\n",
    "from eflow.utils.modeling_utils import optimize_model_grid\n",
    "from eflow.utils.eflow_utils import get_type_holder_from_pipeline, remove_unconnected_pipeline_segments\n",
    "from eflow.utils.pandas_utils import data_types_table\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Additional add ons\n",
    "# !pip install pandasgui\n",
    "# !pip install pivottablejs\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Project Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"Datasets/titanic_train.csv\"\n",
    "\n",
    "# -----\n",
    "dataset_name = \"Titanic Data\"\n",
    "pipeline_name = \"Titanic Pipeline\"\n",
    "\n",
    "# -----\n",
    "\n",
    "\n",
    "# -----\n",
    "notebook_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean out segment space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_unconnected_pipeline_segments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path)\n",
    "shape_df = pd.DataFrame.from_dict({'Rows': [df.shape[0]],\n",
    "                                   'Columns': [df.shape[1]]})\n",
    "display(shape_df)\n",
    "display(df.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and init df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option: 1\n",
    "# df_features = get_type_holder_from_pipeline(pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option: 2\n",
    "df_features = DataFrameTypes()\n",
    "df_features.init_on_json_file(os.getcwd() + f\"/eflow Data/{dataset_name}/df_features.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.display_features(display_dataframes=True,\n",
    "                             notebook_mode=notebook_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Any extra processing before eflow DataPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup pipeline structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipe = DataPipeline(pipeline_name,\n",
    "                         df,\n",
    "                         df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipe.perform_pipeline(df,\n",
    "                           df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate out data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=df_features.target_feature()).values\n",
    "y = df[df_features.target_feature()].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=517, stratify=y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_order = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Models and view results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best parameters for model\n",
    "param_grid = {\n",
    "    \"max_depth\": list(range(1, 4)),\n",
    "#     \"min_samples_leaf\": list(range(80, 130, 5)),\n",
    "#     \"criterion\": [\"gini\", \"entropy\"],\n",
    "#     \"n_splits\": [20, 30]\n",
    "}\n",
    "\n",
    "model, best_params = optimize_model_grid(\n",
    "    model=DecisionTreeClassifier(),\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1_micro\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = repr(model).split(\"(\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_analysis = ClassificationAnalysis(dataset_name=dataset_name,\n",
    "                                        model=model,\n",
    "                                        model_name=model_name,\n",
    "                                        feature_order=feature_order,\n",
    "                                        target_feature=df_features.target_feature(),\n",
    "                                        pred_funcs_dict={\"Probabilities function\":model.predict_proba,\n",
    "                                                         \"Predict function\":model.predict},\n",
    "                                        sample_data=X_train[0],\n",
    "                                        notebook_mode=notebook_mode,\n",
    "                                        df_features=df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_analysis.perform_analysis(X=X_train,\n",
    "                                y=y_train,\n",
    "                                dataset_name=\"Train Data\",\n",
    "                                thresholds_matrix=[[.0,.0],\n",
    "                                                   [.12,.04]],\n",
    "                                classification_error_analysis=True,\n",
    "                                classification_correct_analysis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_analysis.perform_analysis(X=X_test,\n",
    "                                y=y_test,\n",
    "                                dataset_name=\"Test Data\",\n",
    "                                thresholds_matrix=[[.0,.0],\n",
    "                                                   [.12,.04]],\n",
    "                                classification_error_analysis=True,\n",
    "                                classification_correct_analysis=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
