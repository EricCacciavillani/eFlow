{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from eflow.foundation import DataPipeline\n",
    "from eflow.foundation import DataFrameTypes\n",
    "from eflow.data_analysis import FeatureAnalysis\n",
    "from eflow.data_analysis import NullAnalysis\n",
    "from eflow.model_analysis import ClassificationAnalysis\n",
    "from eflow.utils.pandas_utils import data_types_table, value_counts_table, suggest_removal_features \n",
    "from eflow.utils.modeling_utils import optimize_model_grid\n",
    "from eflow.data_pipeline_segments import DataTransformer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scikitplot as skplt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.getipython import get_ipython\n",
    "import ipython_blocking\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Blue\n",
      "1    Blue\n",
      "2     NaN\n",
      "3    Blue\n",
      "4    Blue\n",
      "5     Red\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "s = pd.Series([\"Blue\", \"Blue\", np.nan, \"Blue\",\"Blue\",\"Red\"])\n",
    "\n",
    "print(s.interpolate())\n",
    "print(s.ffill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Additional add ons\n",
    "# !pip install pandasgui\n",
    "# !pip install pivottablejs\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juypter notebook generating cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note: Replace if set to True will remove all the contents of whatever cell it is called in. But it can be undone with a simple CMD + Z. ðŸ™‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: http://tinyurl.com/y6mghyzl\n",
    "def create_new_cell(contents,\n",
    "                    replace=False):\n",
    "    shell = get_ipython()\n",
    "    shell.set_next_input(contents,\n",
    "                         replace=replace)\n",
    "\n",
    "def __format_list_to_string(list_name,\n",
    "                            list_contents):\n",
    "    output_str = f\"{list_name} = [\"\n",
    "    escape_seq_count = 0\n",
    "    final_index = len(list_contents) - 1\n",
    "    req_spacing = len(output_str)\n",
    "\n",
    "    for i,element in enumerate(list_contents):\n",
    "        if i == final_index:\n",
    "            output_str += f'\\\"{element}\\\"'\n",
    "        else:\n",
    "            output_str += f'\\\"{element}\\\",'\n",
    "        \n",
    "        if len(output_str.split(\"\\n\")[escape_seq_count]) > 78:\n",
    "            output_str += \"\\n\"\n",
    "            output_str += (\" \" * req_spacing)\n",
    "            escape_seq_count += 1\n",
    "    output_str += \"]\"\n",
    "    return output_str\n",
    "        \n",
    "# Jupyter block filled with removal features.\n",
    "def create_new_cell_with_removal_features(df,\n",
    "                                          replace=False):\n",
    "    \"\"\"\n",
    "    df:\n",
    "        Pandas DataFrame object\n",
    "    Returns/Desc:\n",
    "        Creates a new cell block in the same block\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get suggestions for removal\n",
    "    cell_content = __format_list_to_string(\"removal_features\",\n",
    "                                           suggest_removal_features(df))\n",
    "    # Add a sort of calling card of where the \n",
    "    cell_content = f\"# create_new_cell_with_removal_features(df,replace={replace})\\n\" + cell_content\n",
    "    create_new_cell(cell_content,\n",
    "                    replace=replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Project Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interaction required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"Datasets/titanic_train.csv\"\n",
    "pre_processing_name = \"Devolpment\"\n",
    "post_processing_name = \"Cleaned data\"\n",
    "dataset_name = dataset_path.split(\"/\")[-1].split(\".\")[0]\n",
    "notebook_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path)\n",
    "display(df.shape)\n",
    "display(df.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction tools for quick analysis dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Great interface; pauses the program;\n",
    "comment on/off at free will;\n",
    "you will need to reset kernel after use more than likely.\n",
    "\"\"\"\n",
    "# from pandasgui import show as qt_display\n",
    "# qt_display(df)\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_ui(df,\n",
    "#          outfile_path='Piviot_Table_JS.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skim through Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_name in df.columns:\n",
    "    print(f'******* Feature: {feature_name} *******')\n",
    "    print(f'Type: {df[feature_name].dtype}')\n",
    "    display(value_counts_table(df,\n",
    "                               feature_name))\n",
    "    print(\"-------\" * 4 + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mark target feature; set to None if not needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction required for supervised learning problems (Can be set to None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = \"Survived\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if target_feature:\n",
    "        df[target_feature]\n",
    "except KeyError:\n",
    "    raise KeyError(f\"The target feature \\'{target_feature}\\' was not found in the dataframe!\"\n",
    "                   + \" Please select a valid feature from the dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipe = DataPipeline(\"Titanic pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: When starting the project uncomment the function to get suggestions and then run the cell again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_new_cell_with_removal_features(df,replace=True)\n",
    "removal_features = [\"Name\",\"Ticket\",\"PassengerId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformer = DataTransformer()\n",
    "data_transformer.remove_features(df,\n",
    "                                 removal_features)\n",
    "data_transformer.perform_segment(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipe.add(\"Remove Unwanted Features\",\n",
    "              data_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipe.generate_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformer.generate_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = widgets.SelectMultiple(\n",
    "#     options=['Apples', 'Oranges', 'Pears'],\n",
    "#     value=['Oranges'],\n",
    "#     #rows=10,\n",
    "#     description='Fruits',\n",
    "#     disabled=False\n",
    "# )\n",
    "# del w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null_analysis = NullAnalysis(project_sub_dir=pre_processing_name,\n",
    "#                              notebook_mode=notebook_mode)\n",
    "# null_analysis.perform_analysis(df,\n",
    "#                                dataset_name)\n",
    "\n",
    "# del null_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Unwanted Columns due to illogical nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any features that have to many nulls/we can't or shouldn't perform any special logic to determine the closest or actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_null_features = [\"Cabin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=remove_null_features,\n",
    "        inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Feature manipulation that data pipelines can't handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sex\"] = df[\"Sex\"] == \"male\"\n",
    "df[\"Sex\"][0] = np.nan\n",
    "df[\"Parch\"][0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrameTypes(df,\n",
    "               ignore_nulls=True,\n",
    "               display_init=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to change/assert feature data types for analysis and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for function_order in range(1,2):\n",
    "    print(function_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_id = None\n",
    "isinstance(segment_id,str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make given data type changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "convert_to_bool = []\n",
    "convert_to_categorical = []\n",
    "df_features = DataFrameTypes(df,\n",
    "                             ignore_nulls=True,\n",
    "                             display_init=False)\n",
    "\n",
    "\n",
    "def __bool_check(feature_values):\n",
    "    feature_could_be_bool = False\n",
    "    \n",
    "    if len(feature_values) == 2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def __categorical_check(feature_name,\n",
    "                        feature_values):\n",
    "    # Categorical check\n",
    "    last_val = None\n",
    "    categorical_flag = True\n",
    "    \n",
    "    for val in feature_values:\n",
    "        if not last_val:\n",
    "            last_val = val\n",
    "            continue\n",
    "        if np.abs(val - last_val) != 1:\n",
    "            categorical_flag = False\n",
    "            break\n",
    "        else:\n",
    "            last_val = val\n",
    "    return categorical_flag\n",
    "\n",
    "def __numeric_check(feature_name,\n",
    "                    feature_values):\n",
    "    float_check = False\n",
    "    for val in feature_values:\n",
    "        try:\n",
    "            float(val)\n",
    "        except ValueError:\n",
    "            return False,False,False\n",
    "        \n",
    "        val = str(val)\n",
    "        tokens = val.split(\".\")\n",
    "        if len(tokens) > 1 and int(tokens[1]) > 0:\n",
    "            float_check = True\n",
    "    \n",
    "    return True, float_check, not float_check\n",
    "    \n",
    "\n",
    "features_flag_types = dict()\n",
    "for feature_name in df.columns:\n",
    "    feature_values = set(df[feature_name].dropna())\n",
    "    flag_type_results = dict()\n",
    "    \n",
    "    # Ignore all string features\n",
    "    if feature_name in df_features.get_string_features():\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    # Features that must be these set types\n",
    "    if feature_name in df_features.get_categorical_features():\n",
    "        continue\n",
    "    if feature_name in df_features.get_bool_features():\n",
    "        continue\n",
    "    \n",
    "    # Bool check\n",
    "    flag_type_results[\"Bool\"] = __bool_check(feature_values)\n",
    "    flag_type_results[\"Categorical\"] = __categorical_check(feature_name,\n",
    "                                                           feature_values)\n",
    "    numeric_flag, float_flag, int_flag = __numeric_check(feature_name,\n",
    "                                                         feature_values)\n",
    "    flag_type_results[\"Numeric\"] = numeric_flag\n",
    "    flag_type_results[\"Float\"] = float_flag\n",
    "    flag_type_results[\"Integer\"] = int_flag\n",
    "    \n",
    "#     float_count = 0\n",
    "#     integer_count = 0\n",
    "#     string_count = 0\n",
    "    \n",
    "#     print(feature_name)\n",
    "#     for entry in feature_values:\n",
    "#         entry = str(entry)\n",
    "#         print(entry)\n",
    "    features_flag_types[feature_name] = flag_type_results\n",
    "features_flag_types\n",
    "a = pd.DataFrame.from_dict(features_flag_types, orient='index')\n",
    "a.index.rename(\"Features\",inplace=True)\n",
    "\n",
    "print(\"Not displaying all features; just those that probably need changing.\")\n",
    "display(a)\n",
    "del a\n",
    "del df_features\n",
    "\n",
    "# Dear future Eric: This code was designed to handle numerical problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Pclass\"] = df[\"Pclass\"].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(\"clamping down my run all with an error. lol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final look at data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up DataFrameTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = DataFrameTypes(df,\n",
    "                             ignore_nulls=True,\n",
    "                             display_init=True)\n",
    "\n",
    "method_to_call = getattr(df_features, 'get_integer_features')\n",
    "\n",
    "result = method_to_call(exclude_target=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(df[\"Embarked\"].dtype) == \"object\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform quick analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_analysis = FeatureAnalysis(project_sub_dir=project_sub_dir)\n",
    "feature_analysis.perform_analysis(df,\n",
    "                                  df_features,\n",
    "                                  dataset_name=\"All Data\")\n",
    "raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from impyute.imputation.cs import mice\n",
    "\n",
    "# a = df[\"Age\"].tolist()\n",
    "# # start the MICE training\n",
    "# imputed_training=mice(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datawig\n",
    "\n",
    "# df_train, df_test = datawig.utils.random_split(df)\n",
    "\n",
    "# #Initialize a SimpleImputer model\n",
    "# imputer = datawig.SimpleImputer(\n",
    "#     input_columns=['Survived', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Fare', 'Cabin','Embarked'], # column(s) containing information about the column we want to impute\n",
    "#     output_column= 'Age', # the column we'd like to impute values for\n",
    "#     output_path = 'imputer_model' # stores model data and metrics\n",
    "#     )\n",
    "\n",
    "# #Fit an imputer model on the train data\n",
    "# imputer.fit(train_df=df, num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputed_training=mice(df[df_features.get_numerical_features()].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "test = df.drop(columns=[\"Date_test\", \"Embarked\"]).dropna()\n",
    "\n",
    "test[\"Sex\"] = df[\"Sex\"] == \"male\"\n",
    "test[target_column] = [random.randint(0, 2) for _ in range(0,test.shape[0])]\n",
    "print(len(test[target_column]))\n",
    "\n",
    "y = test[target_column].values\n",
    "X = test.values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "df_features = DataFrameTypes(test,\n",
    "                             target_column=target_column,\n",
    "                             ignore_nulls=True) \n",
    "df_features.get_all_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=517, stratify=y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(set(y_train))\n",
    "set(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best parameters for model\n",
    "param_grid = {\n",
    "    \"max_depth\": list(range(2, 3)),\n",
    "    \"min_samples_leaf\": list(range(80, 130, 5)),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "#     \"n_splits\": [20, 30]\n",
    "}\n",
    "\n",
    "model, best_params = optimize_model_grid(\n",
    "    model=DecisionTreeClassifier(),\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1_macro\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_analysis = ClassificationAnalysis(model=model,\n",
    "                                     pred_funcs_dict={\"Probabilities function\":model.predict_proba,\n",
    "                                                      \"Predict function\":model.predict},\n",
    "                                     sample_data=X_train,\n",
    "                                     model_name=repr(model).split(\"(\")[0],\n",
    "                                     project_name=f'{parent_project_name}/Classification Analysis',\n",
    "                                     notebook_mode=True,\n",
    "                                     df_features=df_features)\n",
    "\n",
    "dt_analysis.perform_analysis(X=X_train,\n",
    "                             y=y_train,\n",
    "                             dataset_name=\"Training Data\",\n",
    "                             thresholds_matrix=[[.2,.2,.2,.2,.2,.2,.2,.2,.2,.2,.2],\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(\"/Users/ericcacciavillani/Desktop/Coding/Python_Files/Artificial_Intelligence/Data Mining/eFlowMaster/Testing/eFlow Data/Pre processing/Supervised Analysis/DecisionTreeClassifier/Probabilities function/Thresholds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_unique_directory_path(os.getcwd() + \"/eFlow Data/Pre processing/Supervised Analysis/DecisionTreeClassifier/Test data/Probability Classification/\",\n",
    "                        \"Model Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_string = os.getcwd().replace(\"/\", \"///\")\n",
    "error_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = \"/Users/ericcacciavillani/Desktop/Coding/Python_Files/Artificial_Intelligence/Data Mining/eFlowMaster/Testing/eFlow Data/Pre processing/Supervised Analysis/DecisionTreeClassifier/Test data/Probability Classification\"\n",
    "correct_directory_path(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[[1,2],[1,2,3],[1]]\n",
    "c = copy.deepcopy(a)\n",
    "b=np.array(a)\n",
    "b.tolist()\n",
    "hhh = None\n",
    "if hhh:\n",
    "    print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb = None\n",
    "\n",
    "if not bbb:\n",
    "    print(\"test\")\n",
    "else:\n",
    "    print(\"fff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_y = copy.deepcopy(y_test)\n",
    "vector_y = np.where(vector_y==0, \"Test\", vector_y) \n",
    "vector_y = np.where(vector_y=='1', \"Blarg\", vector_y)\n",
    "vector_y = np.where(vector_y=='2', \"Dragon\", vector_y)\n",
    "vector_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(vector_y, vector_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0, 0, 8.3, 0, 0, 0, 0, 0, 0, 0, .36]\n",
    "\n",
    "model_output = model.predict_proba(X_train)\n",
    "\n",
    "print(model_output)\n",
    "# Validate probabilities\n",
    "if thresholds:\n",
    "    if isinstance(thresholds, list) or \\\n",
    "            isinstance(thresholds, np.ndarray):\n",
    "        if sum(thresholds) < .98:\n",
    "            print(\"Thresholds didn't add up to 98%-100%! \"\n",
    "                  \"This may cause issues in your results!\")\n",
    "    else:\n",
    "        raise ThresholdType\n",
    "\n",
    "# ---\n",
    "if isinstance(model_output, list):\n",
    "    model_output = np.asarray(model_output)\n",
    "\n",
    "if isinstance(model_output, np.ndarray):\n",
    "    if thresholds:\n",
    "        outputs_passed_threshold = model_output > np.asarray(thresholds)\n",
    "outputs_passed_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "class UnExpectedData(UserWarning, ValueError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = model.predict_proba(X_train)\n",
    "bool_matrix_thresholds = model_output < np.asarray([.2,.2,.2,.2,.2,.2,.2,.2,.2,.2,.2])\n",
    "\n",
    "tmp_matrix = []\n",
    "for bool_vector in bool_matrix_thresholds:\n",
    "    tmp_vector = []\n",
    "    for i,passed in enumerate(bool_vector):\n",
    "        if passed:\n",
    "            tmp_vector.append(model_output[i][0])\n",
    "        else:\n",
    "            tmp_vector.append(float(\"-inf\"))\n",
    "    tmp_matrix.append(tmp_vector)\n",
    "print(tmp_matrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = msno.bar(df[df.columns[df.isna().any()].tolist()],\n",
    "              color=\"#072F5F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.isnull().sum().index.tolist()\n",
    "null_values = df.isnull().sum().values.tolist()\n",
    "null_sorted_features, null_values = zip(*sorted(zip(null_values,\n",
    "                                                    features)))\n",
    "\n",
    "for feature_index, value in enumerate(null_values):\n",
    "    if value == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eflow._hidden.utils.meta_data_identity import check_create_metadata_of_dataframe\n",
    "testing_path = \"/Users/ericcacciavillani/Desktop/Coding/Python_Files/Artificial_Intelligence/Data Mining/eFlowMaster/Testing/eflow Data/Pre processing/Missing Data/All Data\"\n",
    "check_create_metadata_of_dataframe(df,\n",
    "                                   testing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "feature_name = \"Feature_name\"\n",
    "for hash_type in [1,2,3,4,5,6,7,8,9,10]:\n",
    "    result = 0\n",
    "    for char_index, char in enumerate(feature_name):\n",
    "        if hash_type == 1:\n",
    "            result += int(ord(char))\n",
    "        elif hash_type == 2:\n",
    "            result += int(ord(char) + 62 * ord(char))\n",
    "        elif hash_type == 3:\n",
    "            result += int(ord(char) + 147 * ord(char))\n",
    "        elif hash_type == 4:\n",
    "            result += int((ord(char) + 92) * math.pow(ord(char), 3))\n",
    "        elif hash_type == 5:\n",
    "            result += int(ord(char) + 49 * math.pow(ord(char), 2))\n",
    "        elif hash_type == 6:\n",
    "            result += int((23 + ord(char) + 45) * (3 + ord(char) + 2))\n",
    "        elif hash_type == 7:\n",
    "            result += int((ord(char) * 5) + 32 + 8)\n",
    "        elif hash_type == 8:\n",
    "            result += int(math.pow(ord(char), 2))\n",
    "        elif hash_type == 9:\n",
    "            result += int(ord(char) * 2 + 32 + ord(char) * 2 + 5)\n",
    "        elif hash_type == 10:\n",
    "            result += int(ord(char) * 12 + 76 + math.pow(ord(char), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Ticket\"][891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1,2,3]) % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing=[1,2,3]\n",
    "for shit in df.columns:\n",
    "    print(shit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
